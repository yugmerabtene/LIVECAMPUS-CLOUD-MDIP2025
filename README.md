# MODULE-01 
### INTRODUCTION AU DEVOPS

![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/540d4996-fcfc-4e23-9a6e-d36b0628f6de)


Le DevOps est une approche de développement logiciel et d'exploitation informatique qui vise à améliorer la collaboration entre les équipes de développement (Dev) et d'exploitation (Ops). Cette méthode repose sur un ensemble de principes clés résumés par l'acronyme **CALMS** : Culture, Automation, Lean, Measurement, Sharing.

### Les Composants Clés de DevOps

1. **Culture** :
   - **Collaboration et Communication** : Faciliter la communication constante entre les équipes de développement et d'exploitation pour répondre aux besoins complexes des clients et au time to market rapide.
   - **Confiance et Vision Commune** : Partager une vision globale du système d'information et instaurer une confiance mutuelle.
   - **Fail Fast** : Tester rapidement et remettre en question les fonctionnalités pour éviter les erreurs à long terme.

2. **Automation** :
   - **Automatisation des Tâches Répétitives** : Standardiser et automatiser les tâches dès que possible pour gagner en productivité et efficacité.
   - **Intégration et Déploiement Continus (CI/CD)** : Automatiser les processus d'intégration et de déploiement pour accélérer la mise en production et réduire les risques d'erreurs.

3. **Lean** :
   - **Élimination des Gaspillages** : Identifier et éliminer les tâches qui n'apportent pas de valeur ajoutée en les automatisant.
   - **Amélioration Continue** : Travailler en cycles courts (sprints) pour tester, valider et améliorer continuellement les produits.

4. **Measurement** :
   - **Mesures et Tests Continus** : Réaliser des mesures et des tests tout au long du processus pour assurer la qualité et ajuster en permanence.
   - **Feedback Loop** : Collecter et analyser les retours pour améliorer le produit et les processus.

5. **Sharing** :
   - **Partage de Connaissances et Compétences** : Encourager le partage des retours d'expérience, des compétences et des connaissances pour favoriser la transparence et la collaboration.
   - **Événements Collaboratifs** : Organiser des événements informels et conviviaux pour renforcer la cohésion et l'entraide au sein des équipes.

### Les Origines de la Culture DevOps

Le DevOps est né de la nécessité de surmonter les inefficacités dues au cloisonnement des équipes de développement et d'exploitation. Ce mouvement a été initié par des pionniers comme Patrick Debois, qui, en observant les méthodes agiles, a favorisé la collaboration entre équipes pluridisciplinaires. La première conférence officielle utilisant le terme DevOps a eu lieu à Toronto en 2008, organisée par Patrick Debois et Andrew Schafer.

### Fonctionnement du DevOps

Le cycle de vie DevOps se compose de plusieurs processus itératifs et automatisés, souvent appelés **flux** :

1. **Planification Continue** : Diviser le projet en tâches multiples, suivre la progression, et créer des backlogs regroupant les fonctionnalités.
2. **Développement Continu** : Publier fréquemment les versions logicielles en intégrant les aspects de codage, test, révision, et génération de code.
3. **Intégration et Déploiement Continus (CI/CD)** : Détecter et résoudre les problèmes avant qu'ils ne causent d'autres problèmes ou failles de sécurité.
4. **Tests Continus** : Effectuer des tests automatisés à différentes phases du cycle DevOps pour vérifier l'intégrité du code.
5. **Retour Continu** : Collecter et traiter les retours des clients après le déploiement pour améliorer le produit.
6. **Opérations Continues** : Automatiser le lancement et les mises à jour futures du logiciel.

### Les Avantages du DevOps

1. **Vitesse** : Réduction du temps de production et de résolution des problèmes grâce à l'automatisation et aux tests continus.
2. **Rentabilité** : Réduction du Time-to-Market (TTM), permettant à l'entreprise de profiter rapidement de la valeur commerciale du produit.
3. **Agilité** : Capacité à s'adapter rapidement aux changements et à rester flexible face aux nouvelles tendances.
4. **Satisfaction du Client** : Amélioration continue de l'expérience client grâce à des retours réguliers et à une livraison plus rapide des applications.
5. **Montée en Compétences de l'Équipe** : Amélioration constante de la qualité du code et correction rapide des dysfonctionnements, favorisant l'apprentissage et l'évolution des compétences au sein de l'équipe.

### Pour Qui l'Adoption du DevOps Serait-Elle Bénéfique ?

Toute entreprise cherchant à optimiser ses processus de développement et de mise en production de logiciels peut bénéficier du DevOps. En particulier, les entreprises confrontées à une forte compétition et à la nécessité de répondre rapidement aux demandes du marché, comme les entreprises de services numériques (ESN), trouveront dans le DevOps une approche efficace pour rester compétitives et innovantes.


Le DevOps est une culture et une méthodologie qui vise à favoriser la collaboration entre deux domaines souvent cloisonnés : le développement logiciel (Dev) et les opérations informatiques (Ops). Cette approche a pour objectif de surmonter les problèmes de communication et de collaboration qui surviennent lorsque les équipes de développement et d'exploitation travaillent séparément.

Définition de DevOps
DevOps est une combinaison des termes "Development" (développement) et "Operations" (opérations). Il s'agit d'une approche intégrée qui cherche à améliorer la communication, la collaboration et l'intégration entre les équipes de développement de logiciels et les équipes en charge des infrastructures informatiques. Le but principal du DevOps est de livrer des applications de haute qualité de manière rapide, efficace et avec une forte réactivité aux besoins des clients.

Contexte et Importance de DevOps
Traditionnellement, les équipes de développement se concentraient sur la création et l'amélioration des applications, tandis que les équipes d'exploitation étaient responsables de la stabilité et du déploiement en production. Cette séparation créait souvent un "mur de confusion" où le code qui fonctionnait bien dans l'environnement de développement posait des problèmes en production, conduisant à des tensions et à des blâmes réciproques entre les équipes.

Le DevOps intervient pour éliminer ce mur de confusion en :

Facilitant la Communication et la Collaboration : Encourager les équipes Dev et Ops à travailler ensemble dès le début du projet pour partager les outils, les pratiques et les responsabilités.
Automatisant les Processus : Utiliser des outils d'intégration et de déploiement continus pour automatiser les tests, l'intégration, et le déploiement du code, réduisant ainsi les erreurs humaines et les délais de mise en production.
Adoptant une Approche Agile : Travailler en cycles courts (sprints) pour tester et valider les fonctionnalités en continu, permettant des ajustements rapides en fonction des retours des utilisateurs.
Mesurant et Améliorant en Continu : Utiliser des métriques et des feedbacks constants pour améliorer les processus et la qualité du produit final.


![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/3c3852ea-bf5a-4210-bab3-d5052c089e7a)


Objectifs et Bénéfices de DevOps
L'objectif ultime de DevOps est de satisfaire le client en livrant des produits de haute qualité, développés rapidement et à moindre coût. Parmi les bénéfices principaux de cette approche, on retrouve :

Amélioration de la Qualité : Les tests continus et l'intégration constante permettent de détecter et corriger les problèmes plus tôt dans le cycle de développement.
Réduction des Temps de Mise sur le Marché (Time-to-Market) : L'automatisation des déploiements et des tests réduit le temps nécessaire pour livrer de nouvelles fonctionnalités ou corrections de bugs.
Flexibilité et Réactivité : La capacité à s'adapter rapidement aux nouvelles demandes et aux changements du marché.
Satisfaction Client : L'implication continue des utilisateurs et la livraison rapide de nouvelles fonctionnalités assurent que les produits répondent mieux aux attentes des clients.
Cohésion et Motivation des Équipes : Une meilleure collaboration et communication entre les équipes augmentent la satisfaction et la motivation des employés, conduisant à une meilleure productivité.

![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/a9a06403-5fc5-47e9-89f9-5b29e0f43491)  

C’est là qu’intervient le DevOps, une nouvelle approche qui permet de casser ce mur de confusion pour faire en sorte que les équipes travaillent ensemble avec tous les acteurs autour du projet. L’objectif commun est alors de satisfaire le client en lui livrant un produit de qualité, au faible coût et qui soit développé rapidement.



### De quoi est composé le DevOps ?

Le DevOps repose sur un ensemble de principes fondamentaux résumés par l'acronyme **CALMS** : Culture, Automation, Lean, Measurement, Sharing (culture, automatisation, sans superflu, mesure, partage).

#### Culture

Le DevOps est avant tout une culture, un état d’esprit. L'objectif principal est de favoriser une collaboration étroite entre les équipes par une communication constante pour répondre aux enjeux actuels et aux besoins des clients dans un environnement où le time to market est de plus en plus rapide. Voici les éléments clés :

- **Collaboration et Communication** : Les équipes de développement (Dev) et d'exploitation (Ops) doivent partager non seulement les outils, mais aussi une estime réciproque et une confiance totale. Une vision globale et partagée du système d’information est essentielle pour faciliter la communication et garantir que tout le monde sait ce qui se passe.
- **Fail Fast** : Il est crucial de tester rapidement et de remettre en question les fonctionnalités pour corriger les erreurs dès qu'elles apparaissent, minimisant ainsi les risques à long terme.

#### Automation (Automatisation)

L’automatisation est essentielle dans DevOps pour augmenter la productivité et l’efficacité. Les principales pratiques incluent :

- **Standardisation et Automatisation des Tâches** : Un maximum de tâches répétitives et manuelles sont automatisées pour réduire le temps de travail consacré à ces tâches et minimiser les erreurs humaines.
- **Intégration et Déploiement Continus (CI/CD)** : Automatiser le processus d'intégration et de déploiement du code permet des mises à jour plus rapides et plus sûres.

#### Lean

L'approche Lean dans DevOps consiste à éliminer les tâches qui n’apportent pas de valeur ajoutée et à optimiser le flux de travail. Les points clés incluent :

- **Identification des Tâches à Valeur Ajoutée** : Les équipes doivent identifier les tâches qui créent de la valeur et automatiser ou éliminer celles qui n'en créent pas.
- **Amélioration de la Qualité** : En se concentrant sur les tâches essentielles, la qualité du travail est améliorée tout en nécessitant moins de temps.

#### Measurement (Mesure)

La mesure et l'analyse sont essentielles pour ajuster les processus et assurer la qualité du produit. Les pratiques incluent :

- **Mesures et Tests Continus** : Réaliser des mesures et des tests tout au long du processus de développement pour identifier et corriger les problèmes rapidement.
- **Analyse des Performances** : Utiliser des métriques pour évaluer les performances et l'efficacité des processus et des produits, permettant des ajustements et des améliorations continus.

#### Sharing (Partage)

Le partage des connaissances et des expériences est au cœur de la culture DevOps. Cela inclut :

- **Transparence et Collaboration** : Les équipes doivent partager leurs retours, compétences et connaissances pour favoriser une collaboration forte et une transparence totale.
- **Partage d’Expériences** : Partager les problèmes, les succès et les échecs permet de créer un environnement d'entraide et d'empathie, renforçant ainsi la cohésion et la performance des équipes.


![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/5a2e7f4b-fec2-4121-811e-2a36587cb18d)  



### Le fonctionnement du DevOps en détail

#### Quelles sont les origines de la culture DevOps ?

Le DevOps est né de la nécessité d'améliorer la collaboration et la communication entre les équipes de développement (Dev) et les opérations (Ops), qui travaillaient traditionnellement de manière isolée. Ce cloisonnement entraînait souvent des heures supplémentaires, des livraisons bâclées et, finalement, un mécontentement du client. 

#### Qui a inventé le DevOps ?

L’un des pionniers de cette approche est l’informaticien belge Patrick Debois. Travaillant en tant qu’administrateur système pour le gouvernement belge, Debois était confronté aux problèmes de cohérence et de communication entre les développeurs et les administrateurs. Cherchant une solution, il a découvert les méthodes agiles, qui favorisent la collaboration entre des équipes pluridisciplinaires et les clients.

#### L'Évolution de DevOps

Patrick Debois a commencé à organiser des groupes de discussion, des forums en ligne et des réunions locales pour échanger des idées sur l'amélioration des processus de développement et d'exploitation. L'aventure du DevOps a pris un tournant décisif lors de la conférence « Agile Infrastructure & Operations » à Toronto en 2008, où Debois et Andrew Schafer ont utilisé pour la première fois le terme "DevOps". Cette conférence a marqué le début de la popularisation du concept.

### Les Principes Fondamentaux du DevOps

Le DevOps repose sur plusieurs principes clés qui visent à améliorer la collaboration entre les équipes et à optimiser les processus de développement et de déploiement de logiciels :

- **Décloisonnement des Équipes** : DevOps met l’accent sur l'élimination des silos entre les équipes de développement et d'exploitation, favorisant une collaboration étroite dès le début du projet.
- **Rapprochement des Métiers** : En intégrant les compétences des développeurs et des administrateurs, DevOps permet de créer des processus plus fluides et efficaces.
- **Implication du Client** : Comme dans toute approche agile, le client est fortement impliqué dans le processus, assurant que le produit final répond bien à ses attentes.

### Les DevOpsDays et la Diffusion Mondiale

Les conférences DevOpsDays, initiées par Patrick Debois, ont joué un rôle crucial dans la diffusion de la culture DevOps à travers le monde. Ces événements permettent aux professionnels de partager leurs expériences, d'apprendre les uns des autres et de promouvoir les meilleures pratiques DevOps.

### L’Importance de la Culture DevOps

Adopter DevOps implique des changements significatifs dans la manière de travailler au sein d'une entreprise. L’état d’esprit est primordial : il s'agit de promouvoir la collaboration, l’automatisation, l’amélioration continue et le partage des connaissances. 

![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/7a7f72ac-a7a3-49c2-b0e4-aad2ff792ae7)


### Le succès d’une démarche DevOps

Le succès d’une démarche DevOps repose principalement sur trois piliers : la culture, l’organisation et la méthodologie. Contrairement à une idée répandue, le DevOps ne se limite pas à l’automatisation des processus. Il s’appuie sur des méthodes issues de la culture Agile, inspirées du courant Lean, pour optimiser les flux de travail et la collaboration inter-équipes.

### Fonctionnement du DevOps en détail

#### Les itérations et les sprints

Dans le cadre d’une approche DevOps, les projets sont découpés en cycles itératifs appelés sprints. Une itération consiste à tester et valider chaque étape du processus de développement avant de passer à la suivante. Cette phase est répétée autant de fois que nécessaire pour assurer la qualité et la stabilité du produit.

Les cycles de mise en production plus courts, rendus possibles par les itérations, facilitent la planification et la gestion des risques. La progression incrémentielle permet de réduire l’impact sur la stabilité du système tout en permettant aux équipes de s’adapter rapidement aux besoins évolutifs des clients.

#### Production incrémentielle

La production incrémentielle, ou incrémentale, consiste à mettre à jour les données en identifiant les différences entre l’état actuel (N) de la base décisionnelle et l’état futur (N+1) de la base de production. Cette approche permet de mettre à jour uniquement les nouvelles données, sans avoir à réécrire tout le code, ce qui optimise le processus de déploiement et de mise à jour.

### Le cycle de vie DevOps

Le cycle de vie DevOps se compose de divers processus de développement itératifs et automatisés appelés flux. Bien que les noms et le nombre de flux puissent varier selon les experts, le tronc commun comprend généralement les éléments suivants :

1. **Planification continue** : Cette phase correspond au plan de production. Le projet est divisé en multiples tâches, et les équipes DevOps conçoivent les fonctionnalités des applications et des systèmes. La création de backlogs regroupant l’ensemble des fonctionnalités est essentielle pour suivre la progression.

2. **Développement continu** : Les versions logicielles sont publiées fréquemment. Tous les aspects du codage, y compris l’écriture, le test, la révision et l’intégration du code, sont inclus dans cette phase.

3. **Intégration continue et déploiement continu** : Les modifications du code sont intégrées et déployées de manière systématique et contrôlée. Chaque problème détecté est résolu immédiatement, réduisant ainsi les risques de failles de sécurité ou de modification de la configuration système.

4. **Tests continus** : Des tests automatisés sont effectués à différentes phases du cycle DevOps pour s’assurer que le code reste intact et fonctionne comme prévu.

5. **Retour continu** : Il est crucial de collecter et traiter les retours des clients même après le déploiement du produit pour l’améliorer continuellement.

6. **Opérations continues** : Le lancement du logiciel et ses futures mises à jour sont automatisés, garantissant ainsi une continuité des opérations et une réactivité accrue aux besoins des utilisateurs.



![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/5fbc2285-3165-47f1-9494-b0d862e8f639)


### Les avantages de travailler selon l’approche DevOps

L’approche DevOps offre de nombreux avantages dont les principaux sont :

#### Vitesse
La vitesse de production et de résolution des problèmes est l'un des grands atouts du DevOps. Grâce aux tests continus et à l'automatisation d'un maximum de tâches, le temps de surveillance et d'intervention est considérablement réduit. En conséquence, le temps nécessaire à l'élaboration d'une application diminue, permettant à l'entreprise de tirer rapidement profit de la valeur commerciale de son produit.

#### Rentabilité
Le Time-to-Market (TTM) est devenu un objectif marketing crucial pour de nombreuses entreprises. Dans le cadre du DevOps, ce TTM représente la durée de développement d'un produit, c'est-à-dire le temps écoulé entre l'idée initiale et la mise sur le marché. Plus ce délai est raccourci, plus une entreprise est perçue comme agile et devance ses concurrents, ce qui augmente sa rentabilité.

#### Agilité de l’entreprise
L'agilité se réfère à la capacité de l'entreprise à s'adapter rapidement aux changements, aux nouvelles tendances et à faire preuve de flexibilité. Cette compétence est essentielle pour une Entreprise de Services Numériques (ESN) qui doit constamment innover pour rester à la pointe.

#### Satisfaction du client
L'une des caractéristiques clés du DevOps est l'amélioration continue de l'expérience client en l'impliquant au maximum grâce au flux « retour continu ». Les retours réguliers des clients permettent de livrer des applications qui correspondent au mieux à leurs attentes. Ainsi, le travail itératif et les retours fréquents assurent une adaptation rapide et précise aux besoins des clients.

#### Montée en compétences de l'équipe
Le cycle de vie du DevOps, basé sur l'itération et les sprints, améliore constamment la qualité du code. Chaque dysfonctionnement est corrigé rapidement, ce qui permet une amélioration continue des compétences des équipes. Par exemple, selon le rapport State of DevOps de 2019, les organisations les plus performantes réalisent des déploiements de code 208 fois plus fréquents et rétablissent les services après un incident 2604 fois plus rapidement.

### Pour qui l'adoption du DevOps serait-elle bénéfique ?

Aujourd'hui, presque toutes les entreprises peuvent bénéficier de l'adoption du DevOps. Avec l'avènement de la transformation numérique, chaque acteur économique, quel que soit son secteur d'activité, doit intégrer des pratiques numériques innovantes pour rester compétitif. Un exemple notable est celui de Nike, qui a embrassé cette transformation avec succès.

### Exemple : Nike, une entreprise technologique

John Donahoe, PDG de Nike depuis 2019, a déclaré : « We are a Tech Company ». Cette affirmation souligne l'évolution de Nike d'une entreprise industrielle à une véritable entreprise technologique. Plusieurs aspects illustrent cette transformation :
- **Intimité client** : Nike propose des produits et services personnalisés via ses applications, assurant une relation continue avec les clients.
- **Gratuité** : Les applications Nike Training Club et Nike Running Club sont gratuites, encourageant une utilisation massive et fidèle.
- **Création de valeur inversée** : Nike commence par identifier les besoins de chaque client pour proposer une offre personnalisée.
- **Temps réel** : Avec des outils comme Splunk, Nike ajuste ses stocks et optimise ses ventes en temps réel.
- **Proximité avec le monde de l’IT** : Nike organise des TED Talks, des hackathons et a créé des incubateurs technologiques.

### Les quatre domaines essentiels pour réussir avec DevOps

Pour réussir une adoption DevOps, il est crucial de se concentrer sur quatre domaines :

1. **Modernisation des plateformes** : Assurez-vous que votre entreprise dispose de la flexibilité et de l'évolutivité nécessaires pour répondre aux demandes des clients.
2. **Modernisation des applications** : Adoptez les meilleures pratiques de développement pour faciliter les déploiements futurs.
3. **Automatisation de l’environnement informatique** : Intégrez l'automatisation autant que possible pour améliorer l'efficacité opérationnelle.
4. **Transformation continue** : Innovez en permanence pour garantir la longévité et la pertinence de votre entreprise dans un marché en constante évolution.



![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/687fceb4-343a-4bc5-beb0-c95e90a5bcd1)  


### Adopter une nouvelle culture

Pour réussir une démarche DevOps, il est crucial de mener un changement culturel au sein de l’organisation. Cela commence par l’adhésion des individus au projet. Le principal défi n’est pas technologique mais humain. Votre capacité à instaurer une culture d’agilité au sein de l’entreprise est déterminante.

Ne sous-estimez pas l’importance de cette conduite du changement. Que ce soit au sein des équipes ou au niveau de la direction, le soutien de tous est essentiel pour mettre en place une démarche DevOps. L’ensemble de l’équipe doit être unie et motivée par le changement à venir.

Il est préférable d’avancer progressivement. Les objectifs initiaux doivent être modestes et facilement atteignables, ce qui facilitera l’acceptation du changement par les équipes. Lorsque le changement se fait en douceur et apporte des résultats positifs, les équipes sont plus enclines à poursuivre dans cette direction.

### Adopter un nouveau processus

Il est indispensable de se familiariser avec les méthodes agiles. Bien que ces méthodes aient prouvé leur efficacité, elles représentent un changement significatif qui peut être difficile à appréhender pour certaines équipes. Il est crucial de bien comprendre et d’expliquer ces méthodes. Pour cela, vous pouvez organiser des formations et faire appel à un coach en agilité qui guidera les projets à travers des workshops, des interviews, et des séminaires sur l’agilité.

Prenez le temps d’évaluer vos pratiques actuelles. Le modèle CALMS (Culture, Automation, Lean, Measurement, Sharing) sert de cadre de référence pour analyser la démarche DevOps. L’objectif est de comprendre ce qui dans vos pratiques relève du DevOps et ce qui en diverge, afin de cibler les éléments à changer.

### Adopter de nouveaux outils

Enfin, réfléchissez aux outils nécessaires pour soutenir votre démarche DevOps. Bien que le DevOps soit avant tout une culture, l’aspect technique est indispensable. 

#### Voici les meilleurs outils DevOps

Les outils DevOps sont nombreux et se répartissent selon les étapes du cycle de vie DevOps. Certains outils combinent plusieurs fonctions :

- **Chaînes d’outils tout-en-un** : Ces suites d’outils intégrés permettent aux équipes de développement et d’exploitation de collaborer efficacement tout au long du cycle de vie du développement logiciel. Exemples : Microsoft Azure DevOps, Atlassian (Jira, Confluence, Bitbucket, Bamboo), GitLab.
- **Chaînes d’outils personnalisés** : Cette option permet de combiner les outils déjà utilisés et connus par les équipes. L’intégration est cruciale pour éviter des pertes de temps et des difficultés de partage d’informations. Choisissez les outils en fonction des besoins de l’entreprise et des équipes.

### Exemples d'outils DevOps

- **Gestion du code source** : Git, GitLab, GitHub, Subversion, Bitbucket.
- **Gestion de la configuration** : Ansible, Terraform, Chef, Puppet.
- **CI/CD (Continuous Integration/Continuous Deployment)** : Jenkins, GitLab CI/CD, Travis CI, CircleCI, Bamboo, Microsoft Azure DevOps, AWS CodePipeline.
- **Tests** : Selenium, JUnit, TestNG, Appium.
- **Monitoring et alerte** : Prometheus, Grafana, Elastic Stack, Datadog, New Relic.
- **Gestion de projet** : Jira, Trello, Asana, GitLab, GitHub, Microsoft Azure DevOps.
- **Cloud providers** : AWS, Microsoft Azure, Google Cloud Platform, Scaleway, Exoscale.

### Métiers utiles au DevOps

Voici quelques-uns des principaux profils impliqués dans le DevOps :

- **Ingénieur DevOps** : Il possède des compétences en développement logiciel et en administration système pour améliorer les pratiques DevOps.
- **Ingénieur Système** : Expert en matériel et logiciels, il optimise l’outil informatique de l’entreprise.
- **Ingénieur Sécurité** : Conçoit des logiciels sécurisés et résilients face à la cybercriminalité.
- **Ingénieur Réseau** : Maintient le fonctionnement des réseaux.
- **Architecte** : Supervise l’architecture globale d’un système logiciel.
- **Intégrateur** : Déploie les solutions IT et automatise les livraisons.
- **Développeur Front-End/Back-End/Fullstack** : Conçoit et assure l’ergonomie des solutions IT.
- **Chef de projet** : Coordonne les équipes et assure l’avancement des projets.
- **Coach Agile / Scrum Master** : Accompagne et forme les équipes dans la transition vers l’agilité.

### Le marché de l'emploi autour du DevOps

Le marché de l’emploi autour du DevOps est en pleine expansion. En mars 2023, LinkedIn affichait plus de 16 000 offres en France avec le mot-clé "DevOps", et Welcome to the Jungle en recensait plus de 2 500. Cependant, il y a une pénurie de talents par rapport aux offres disponibles.

Selon Sacha Kalusevic de Michael Page Tech, le secteur IT ne devrait pas connaître de crise de l’emploi en 2023 malgré les tensions et la pénurie de main-d’œuvre. La Dares prévoit que les difficultés de recrutement pour les ingénieurs informatiques pourraient s’accentuer d’ici 2030.


### La Relation entre DevOps et le Cloud

Le Cloud a radicalement transformé la manière dont les équipes créent, déploient et exploitent des applications, agissant comme un catalyseur puissant pour la transformation DevOps.

#### Le Cloud comme Accélérateur de la Transformation DevOps

Le lien entre le Cloud et le DevOps est fondamental. Bien que le DevOps puisse fonctionner sans le Cloud, l'intégration des services Cloud en améliore considérablement les avantages. Voici quelques-unes des caractéristiques du Cloud qui renforcent les pratiques DevOps :

- **Évolutivité** : Les services Cloud permettent de provisionner rapidement des ressources pour répondre à la demande sans les délais liés aux approbations budgétaires et à l'installation de nouveaux matériels.
- **Flexibilité** : Le Cloud offre la possibilité de déployer rapidement des infrastructures de test et de développement sans investissement lourd en infrastructures physiques et licences logicielles.
- **Automatisation** : Les services Cloud s'intègrent facilement aux outils d'automatisation, facilitant la mise en place de pipelines CI/CD (Continuous Integration/Continuous Deployment) pour des déploiements rapides et fiables.
- **Collaboration** : Les plateformes Cloud sont conçues pour être partagées, favorisant la collaboration entre les équipes de développement et d'opérations.
- **Sécurité** : Les fournisseurs de services Cloud offrent des niveaux de sécurité élevés et des fonctionnalités de conformité réglementaire, aidant les équipes DevOps à sécuriser leurs applications et données.

Les grands acteurs de l'informatique proposent désormais des services spécifiquement orientés DevOps, tels que AWS DevOps, Google Cloud DevOps, et Azure DevOps.

### Le Lien entre DevOps et CI/CD

Le CI/CD (Continuous Integration/Continuous Delivery) est une composante clé de DevOps. Il s'agit de flux de travail qui intègrent de l'automatisation et de la surveillance continue dans le processus de déploiement des applications, permettant une résolution rapide des dysfonctionnements et des déploiements plus rapides.

#### CI/CD comme Composante de DevOps

- **Automatisation** : Les pipelines CI/CD automatisent les processus de build, de test et de déploiement, réduisant les erreurs humaines et accélérant les livraisons.
- **Surveillance Continue** : La surveillance continue détecte rapidement les problèmes et assure la stabilité et la performance des applications.

En somme, le CI/CD se concentre sur l'amélioration du processus de déploiement, tandis que DevOps englobe une culture et une organisation du travail plus larges, intégrant des pratiques agiles et collaboratives.

### DevOps vs. Scrum

Scrum et DevOps sont souvent confondus, mais ils diffèrent fondamentalement :

- **Scrum** : C'est un framework de gestion de projet agile qui structure le travail en sprints courts, avec des réunions régulières pour évaluer les progrès et ajuster les plans.
- **DevOps** : C'est une philosophie et une approche culturelle qui vise à fluidifier et automatiser le cycle de vie des applications, intégrant étroitement les équipes de développement et d'opérations.

### DevOps vs. DevSecOps

DevSecOps intègre la sécurité dès le début du cycle de développement et de déploiement, répondant aux défis posés par l'augmentation de la cybercriminalité :

- **DevOps** : Met l'accent sur la vitesse et la performance, souvent en négligeant les aspects de sécurité.
- **DevSecOps** : Ajoute une couche de sécurité, intégrant les contrôles de sécurité dans chaque étape du processus DevOps pour assurer la protection continue des applications.

Selon le rapport 2020 du State of DevOps, 75% des entreprises avec un haut niveau de maturité DevOps peuvent remédier aux vulnérabilités de sécurité en moins d’une journée, illustrant l'efficacité de l'approche DevSecOps.


----
# MODULE-02 

**Déployer du code en production : bonnes pratiques (exemple avec EC2)**

----

## Chapitre-01 Comprendre les bonnes pratiques de déploiement de code en production :


Le MODULE-02 vise à fournir une compréhension approfondie des meilleures pratiques pour déployer du code en production sur AWS ECS (Elastic Container Service). Nous explorerons également le rôle crucial de S3 (Simple Storage Service) dans le stockage des artefacts de déploiement, tels que les fichiers de configuration, les scripts de déploiement, les packages d'application, etc., qui peuvent être récupérés lors du déploiement sur ECS. Cette approche garantit la cohérence des versions déployées dans différents environnements et réduit le risque d'introduire des erreurs lors du déploiement. De plus, nous mettrons en évidence l'importance de la documentation et de la communication lors des déploiements pour assurer une transition fluide vers les nouvelles versions du logiciel.

- **Partie-01 Intégration continue avec AWS ECS, S3 et GitOps**

L'intégration continue (CI) est une pratique essentielle pour les développeurs travaillant avec AWS ECS et S3. Elle consiste à intégrer toutes les modifications de code dans une branche principale aussi souvent que possible, permettant d'identifier rapidement les défaillances. Sur AWS, les pipelines CI peuvent être implémentés à l'aide de services tels que AWS CodePipeline, qui peuvent déclencher des actions automatisées à chaque modification de code. En intégrant GitOps dans le processus, vous pouvez stocker l'infrastructure déclarative dans des dépôts Git, assurant ainsi la traçabilité et la reproductibilité des déploiements.

## Intégration continue : le code, les livrables et les environnements

![Intégration continue](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/e9d35bed-b606-4e55-b7fa-91a38a528f99)

### Les grands principes de l'intégration continue

L'intégration continue est un ensemble de pratiques visant à livrer efficacement le code logiciel produit par les équipes de développement. Parmi les objectifs principaux, on trouve :

- **Automatisation des builds, livraisons et déploiements** : Réduire les actions manuelles pour minimiser les erreurs humaines et permettre aux experts de se concentrer sur leur produit.
- **Feedback rapide** : Fournir une visibilité sur les impacts des modifications du code, permettant aux développeurs d'intégrer sereinement leurs changements.

### Du code source aux environnements

L'intégration continue concerne l'intégration du nouveau code, la livraison continue des livrables et le déploiement continu des produits. Voici quelques questions fréquentes :

- Quelle est la différence entre la promotion du code, des livrables et des environnements ?
- Comment relier le déploiement en production à la branche master du dépôt de code ?
- Quels automatismes mettre en place pour assurer la cohérence entre le dépôt de code et les environnements de l'application ?

Ces questions varient selon le contexte technique, le projet, le secteur d'activité et la maturité des processus. L'objectif est de détailler les concepts sans dépendre d'outils spécifiques, bien que certains outils facilitent la mise en œuvre.

### Le concept du "build once"

![Build Once](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/40d9e1e7-1594-42bb-9121-ae21b252afbf)

Un principe clé de l'intégration continue est le "build once", c'est-à-dire ne construire un livrable qu'une seule fois après modification du code. Cela réduit le risque de créer un livrable différent lors de déploiements ultérieurs.

#### Risques de re-build :

- Problèmes de machine (disque plein, etc.)
- Soucis de réseau
- Problèmes liés à l'outil de build (maintenance, indisponibilité)
- Versions différentes des dépendances du produit
- Utilisation involontaire d'une version différente du code

Pour éviter ces risques, il est préférable de construire une seule fois le livrable puis de l'utiliser tel quel lors des déploiements, c'est la pratique du "build once".

### La promotion des livrables

![Promotion des livrables](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/35a11b22-e653-498d-b82f-f19d0aaaba62)

Une fois le livrable créé, il doit subir divers tests avant la mise en production. On utilise des "étagères" pour stocker les livrables et suivre leur avancement. Ces étagères peuvent être :

- Gestionnaires de livrables
- Dossiers de livraison
- Archivage d'artefacts
- Dépôts d'images Docker

Chez AT Internet, nous utilisons quatre étagères (dev, integ, preprod, prod) et une supplémentaire (staging) pour les livraisons urgentes de correctifs.

#### Promotion des livrables

Le passage d'un livrable d'une étagère à l'autre est conditionné par le succès de différentes phases de tests. La promotion implique souvent une simple copie plutôt qu'un déplacement.

### Les environnements de dev

![Environnements de dev](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/d869271d-18ad-4792-9101-830f05860665)

Une fois les livrables obtenus et stockés, ils doivent subir différentes étapes de test et de validation avant la mise en production. Chaque livrable est déployé sur l'environnement auquel il est candidat pour des tests dynamiques, dits "boîte noire".

#### Développement

La première phase de déploiement consiste à valider la mécanique de déploiement et les propriétés du système sur l'environnement de développement.

#### Intégration

La validation de scénarios transversaux est effectuée sur l'environnement d'intégration pour assurer la compatibilité avec les autres systèmes.

#### Préproduction

Dernière phase de tests avant la mise en production, souvent liée à des décisions marketing ou commerciales. Si des bugs sont détectés à ce stade, cela indique un manque de tests dans les étapes précédentes.

#### Staging

Le staging permet de valider rapidement une correction à apporter en production, en déployant le code actuel avec la seule modification du correctif.

#### Production

Certaines validations peuvent se dérouler en production, telles que les "Tests Post Déploiement" pour vérifier les aspects environnementaux et les configurations spécifiques.

### L'automatisation de la livraison

![Automatisation](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/f9acf27c-0039-4457-b718-446186885ab1)

L'orchestration de la livraison d'un produit logiciel doit être systématique et répétitive. L'automatisation permet d'atteindre cet objectif en utilisant des outils tels que Jenkins, Travis CI, GitlabCI, etc.

#### Publication des livrables

La publication consiste à déposer le livrable sur une étagère en fonction de la branche de code considérée. Voici les chemins de publication identifiés :

- Branche ‘develop’ : livrables candidats à l’environnement de ‘développement’
- Branche ‘release’ : livrables candidats à l’environnement de ‘préproduction’
- Branche ‘hotfix’ : livrables candidats à l’environnement de ‘staging’

#### Promotion automatisée

L’automatisation de la promotion des livrables peut inclure :

- Promotion intégration > préproduction
  - Fusion du code de ‘develop’ vers ‘release’
  - Incrémentation de la version mineure et remise à ‘0’ de la version patch sur ‘develop’
- Promotion préproduction > production
  - Fusion du code de ‘release’ vers ‘master’
  - Application d’un tag sur ‘master’
- Promotion staging > production
  - Fusion du code de ‘hotfix’ vers ‘master’
  - Application d’un tag sur ‘master’

### L'intégration dis-continue

![Intégration dis-continue](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/5b5eb71a-56c8-4f8e-9477-de7fb2ef5e9a)

Le flux idéal de livraison continue nécessite divers automatismes et outils pour valider progressivement les produits. Cependant, il manque souvent certains éléments dans la chaîne, ce qui conduit à une intégration dis-continue. Voici l’ordre typique de mise en place des éléments :

1. Construction du livrable (build)
2. Tests unitaires
3. Scripts de déploiement
4. Qualité de code
5. Déclenchement des tests
6. Mécaniques de promotions

Lorsqu’un ou plusieurs de ces éléments manquent, l’opération reste manuelle. À un niveau de maturité supérieur, toutes les opérations sont automatisées, mais des actions manuelles peuvent encore être nécessaires pour déclencher les mises en production jusqu’à ce que la confiance dans le système soit suffisante pour une automatisation complète.



- **Partie-02 Créer des pipelines qui permettent une itération rapide**

Les pipelines CI/CD sur AWS doivent être optimisés pour une itération rapide, en particulier lors du développement sur les branches de fonctionnalités. Idéalement, vos pipelines devraient s'exécuter rapidement pour fournir des commentaires instantanés aux développeurs. Vous pouvez utiliser des services tels que AWS CodeBuild pour automatiser les tests, la compilation et la création d'artefacts.

- **Partie-03 Suivre les bonnes pratiques pour la création de conteneurs sur AWS ECS**

Pour déployer des applications sur AWS ECS, il est crucial de suivre les bonnes pratiques pour la création de conteneurs. Cela inclut des recommandations telles que la minimisation de la taille des images, la séparation des données de configuration, et l'utilisation de stratégies de gestion des secrets pour sécuriser les informations sensibles.

- **Partie-04 Mettre en œuvre la sécurité le plus tôt possible dans les pipelines sur AWS**

La sécurité doit être intégrée dès le début du processus de développement sur AWS. Vous pouvez utiliser des outils comme AWS CodeArtifact pour gérer les dépendances et détecter les vulnérabilités dès le stade de la construction. De plus, l'utilisation d'AWS Identity and Access Management (IAM) permet de contrôler l'accès aux ressources AWS de manière granulaire.

- **Partie-05 Livraison continue sur AWS avec ECS, S3 et GitOps**

La livraison continue (CD) sur AWS implique la publication du code à tout moment à l'aide des artefacts générés par les pipelines CI. Les pipelines CD peuvent être configurés pour déployer automatiquement les nouvelles versions d'une application sur AWS ECS, en utilisant des stratégies de déploiement telles que le déploiement bleu-vert pour minimiser les interruptions de service.

- **Partie-06 Séparer les clusters de différents environnements sur AWS ECS**

Il est recommandé d'avoir des clusters ECS distincts pour chaque environnement, tels que le développement, le test et la production, sur AWS. Cela permet d'isoler les charges de travail et de garantir une disponibilité et des performances optimales pour chaque environnement.

- **Partie-07 Maintenir des environnements de préproduction le plus près possible de la production sur AWS**

Les environnements de préproduction sur AWS doivent être aussi similaires que possible à l'environnement de production pour garantir des tests efficaces et réalistes. Cela peut être réalisé en utilisant des configurations et des paramètres similaires entre les environnements, ainsi que des outils comme AWS CloudFormation pour automatiser le déploiement et la gestion des infrastructures.

- **Partie-08 Se préparer à gérer les défaillances en production sur AWS**

La gestion des défaillances en production sur AWS implique la surveillance continue de l'application et de l'infrastructure, ainsi que la mise en place de mécanismes de rollback et de déploiement automatisés. Les services tels que AWS CloudWatch peuvent être utilisés pour surveiller les métriques et les journaux, tandis que les groupes de capacités ECS peuvent être configurés avec des stratégies de déploiement pour gérer automatiquement les défaillances et les mises à jour.

## Chapitre-02 Apprendre à sécuriser les données sensibles.
  
# Apprendre à Sécuriser les Données Sensibles

## Partie 01 : Initiation à la Cryptographie Symétrique et Asymétrique en Shellcode et Python

### Cryptographie

La cryptographie est une technique essentielle pour sécuriser les informations. Il existe principalement deux types de cryptographie : symétrique et asymétrique.

#### Cryptographie Symétrique

La cryptographie symétrique utilise une seule clé pour chiffrer et déchiffrer les informations. Cette méthode est rapide et efficace mais présente des défis en matière de gestion sécurisée des clés.

**Exemple de Cryptographie Symétrique :**

Supposons que Maria veuille envoyer un message chiffré à Jose. Les deux doivent d'abord se mettre d'accord sur une clé commune. Maria utilise cette clé pour chiffrer le message et l'envoie à Jose, qui utilise la même clé pour déchiffrer le message.

**Sécurité des Clés :**

La sécurité en cryptographie symétrique repose entièrement sur la clé. Elle doit être secrète et difficile à deviner. Cependant, la distribution sécurisée de la clé peut être un point faible.

**Histoire de la Cryptographie Symétrique :**

La cryptographie symétrique existe depuis des siècles. Des méthodes basiques étaient utilisées dans l'Égypte ancienne et l'Empire romain. La Seconde Guerre mondiale a vu l'usage intensif de systèmes cryptographiques symétriques sophistiqués pour protéger les messages militaires.

**Claude Shannon : Le Père de la Cryptographie Mathématique :**

En 1949, Claude Shannon a publié "Théorie de la communication des systèmes de secret", modernisant les techniques de chiffrement avec des processus mathématiques avancés. Ses travaux ont jeté les bases de la cryptographie symétrique moderne.
![image](https://github.com/yugmerabtene/LIVECAMPUS-CLOUD-MDIP2025/assets/3670077/935750e3-b113-4601-889d-105522de9f27)


**Exemple en Python avec AES :**

Pour implémenter la cryptographie symétrique avec AES en Python, suivez ces étapes :

1. **Installation de la bibliothèque :**

   ```bash
   pip install cryptography
   ```

2. **Script Python pour le chiffrement et déchiffrement avec AES :**

   ```python
   from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes
   from cryptography.hazmat.primitives import padding
   from cryptography.hazmat.backends import default_backend
   import os

   # Génération d'une clé et d'un IV
   key = os.urandom(32)  # Clé de 256 bits pour AES-256
   iv = os.urandom(16)   # IV de 128 bits

   # Données à chiffrer
   data = b'Voici des données sensibles.'

   # Padding des données
   padder = padding.PKCS7(algorithms.AES.block_size).padder()
   padded_data = padder.update(data) + padder.finalize()

   # Chiffrement
   cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())
   encryptor = cipher.encryptor()
   ciphertext = encryptor.update(padded_data) + encryptor.finalize()

   print(f"Chiffrement : {ciphertext}")

   # Déchiffrement
   decryptor = cipher.decryptor()
   decrypted_padded_data = decryptor.update(ciphertext) + decryptor.finalize()

   # Suppression du padding
   unpadder = padding.PKCS7(algorithms.AES.block_size).unpadder()
   decrypted_data = unpadder.update(decrypted_padded_data) + unpadder.finalize()

   print(f"Déchiffrement : {decrypted_data}")
   ```

3. **Exécution du script en ligne de commande :**

   Sauvegardez le script dans un fichier nommé `aes_example.py`, puis exécutez-le avec la commande suivante :

   ```bash
   python aes_example.py
   ```

**Algorithmes de Chiffrement Symétrique :**

- **DES :** Premier algorithme de chiffrement informatique développé en 1975 par IBM.
- **AES :** Successeur du DES, plus sûr et plus efficace, avec des clés de taille variable et un processus de cryptage en blocs.

**Avantages et Inconvénients :**

- **Avantages :** Rapidité, simplicité, et efficacité pour protéger les données dans les systèmes informatiques actuels.
- **Inconvénients :** Distribution sécurisée des clés nécessaire, vulnérabilité aux attaques par force brute.

#### Cryptographie Asymétrique

La cryptographie asymétrique utilise deux clés distinctes : une clé publique pour chiffrer les données et une clé privée pour les déchiffrer.

**Exemple de Cryptographie Asymétrique :**

Ce type de chiffrement est utilisé pour sécuriser les transactions en ligne, comme les emails ou les transactions sur les réseaux de blockchain.

**Fonctionnement :**

- Chaque partie génère une paire de clés : une clé publique, partagée entre les participants, et une clé privée, gardée secrète.
- L'expéditeur utilise la clé publique du destinataire pour chiffrer les données et signe numériquement le message avec sa clé privée.
- Le destinataire utilise sa clé privée pour déchiffrer le message.

**Exemple en Python avec RSA :**

Pour implémenter la cryptographie asymétrique avec RSA en Python, suivez ces étapes :

1. **Installation de la bibliothèque :**

   ```bash
   pip install cryptography
   ```

2. **Script Python pour le chiffrement et déchiffrement avec RSA :**

   ```python
   from cryptography.hazmat.primitives.asymmetric import rsa, padding
   from cryptography.hazmat.primitives import serialization, hashes

   # Génération d'une paire de clés RSA
   private_key = rsa.generate_private_key(
       public_exponent=65537,
       key_size=2048,
       backend=default_backend()
   )
   public_key = private_key.public_key()

   # Données à chiffrer
   data = b'Voici des données sensibles.'

   # Chiffrement avec la clé publique
   ciphertext = public_key.encrypt(
       data,
       padding.OAEP(
           mgf=padding.MGF1(algorithm=hashes.SHA256()),
           algorithm=hashes.SHA256(),
           label=None
       )
   )

   print(f"Chiffrement : {ciphertext}")

   # Déchiffrement avec la clé privée
   decrypted_data = private_key.decrypt(
       ciphertext,
       padding.OAEP(
           mgf=padding.MGF1(algorithm=hashes.SHA256()),
           algorithm=hashes.SHA256(),
           label=None
       )
   )

   print(f"Déchiffrement : {decrypted_data}")
   ```

3. **Exécution du script en ligne de commande :**

   Sauvegardez le script dans un fichier nommé `rsa_example.py`, puis exécutez-le avec la commande suivante :

   ```bash
   python rsa_example.py
   ```

**Inconvénients et Solutions :**

- **Inconvénients :** Plus lent et plus intensif en calcul que le chiffrement symétrique.
- **Solutions :** Les méthodes de chiffrement hybride combinent les avantages des deux approches. Par exemple, une clé de session générée de manière aléatoire peut être utilisée pour surmonter les limitations de performance.

### Pour résumer

La cryptographie est une technologie essentielle pour protéger les informations sensibles. Les techniques symétriques et asymétriques ont leurs propres avantages et inconvénients. En combinant ces méthodes, on peut obtenir des solutions de sécurité robustes et efficaces pour différents scénarios d'utilisation.

----
# Chapitre-03 Découvrir l’importance du versioning du code et des données sensibles

## Partie-01 Traçabilité et reproductibilité

Le versioning du code permet une traçabilité complète des changements apportés à une application. Chaque modification est enregistrée avec précision, ce qui facilite l'identification des erreurs et la compréhension de l'évolution de l'application au fil du temps. De plus, la reproductibilité des déploiements est garantie, car chaque version du code est stockée avec toutes ses dépendances et configurations associées.

### Exemple de code

Voici un exemple simple utilisant Git pour le versioning du code :

```bash
# Initialiser un dépôt Git
git init

# Ajouter des fichiers au dépôt
git add .

# Commiter les fichiers avec un message de commit
git commit -m "Initial commit"

# Ajouter une nouvelle fonctionnalité
echo "print('Hello, World!')" > hello.py
git add hello.py
git commit -m "Add hello world script"

# Afficher l'historique des commits
git log
```

### Explication détaillée

1. **Initialiser un dépôt Git** : Cette commande crée un nouveau dépôt Git dans le répertoire actuel.
2. **Ajouter des fichiers au dépôt** : Cette commande ajoute tous les fichiers du répertoire au suivi de version.
3. **Commiter les fichiers** : Enregistre un instantané des fichiers dans l'historique du dépôt.
4. **Ajouter une nouvelle fonctionnalité** : Crée un nouveau fichier avec un script simple et le commite dans l'historique.

### Exemple de cas

Imaginez que vous déployez une application web. Grâce au versioning, si une nouvelle fonctionnalité introduit un bug, vous pouvez facilement revenir à la version précédente qui fonctionnait correctement.

### Exercice

1. Créez un dépôt Git.
2. Ajoutez un fichier README.md avec une description de votre projet.
3. Commitez le fichier.
4. Modifiez le fichier pour ajouter plus de détails et commitez à nouveau.
5. Affichez l'historique des commits pour voir les changements.

**Corrigé de l'exercice :**

1. Initialisez un dépôt Git :
   ```bash
   git init
   ```
2. Ajoutez un fichier README.md :
   ```bash
   echo "# Mon Projet" > README.md
   git add README.md
   git commit -m "Ajout du fichier README.md"
   ```
3. Modifiez le fichier README.md :
   ```bash
   echo "## Détails du projet" >> README.md
   git add README.md
   git commit -m "Ajout des détails au README.md"
   ```
4. Affichez l'historique des commits :
   ```bash
   git log
   ```

## Partie-02 Gestion des erreurs et rollback

En cas d'erreur ou de problème après un déploiement en production, le versioning permet aux équipes de développement de revenir à une version précédente du code qui fonctionnait correctement. Cela réduit les temps d'arrêt et minimise les impacts négatifs sur les utilisateurs finaux. Grâce à une gestion efficace des versions, il est possible de réagir rapidement aux problèmes et de restaurer la stabilité du système.

### Exemple de code

```bash
# Revenir au commit précédent
git checkout <commit_hash>

# Annuler le dernier commit
git revert HEAD
```

### Explication détaillée

1. **Revenir au commit précédent** : Cette commande permet de revenir à un état antérieur du code en utilisant le hash du commit.
2. **Annuler le dernier commit** : Crée un nouveau commit qui annule les modifications du commit précédent.

### Exemple de cas

Supposons que vous ayez déployé une nouvelle version de votre application et que des erreurs critiques apparaissent. Avec Git, vous pouvez rapidement revenir à la version précédente qui fonctionnait correctement, minimisant ainsi les interruptions de service.

### Exercice

1. Ajoutez un fichier script.py à votre dépôt Git.
2. Commitez le fichier.
3. Modifiez le fichier pour introduire une erreur et commitez la modification.
4. Utilisez `git revert` pour annuler le commit introduisant l'erreur.

**Corrigé de l'exercice :**

1. Ajoutez un fichier script.py :
   ```bash
   echo "print('Hello, World!')" > script.py
   git add script.py
   git commit -m "Ajout de script.py"
   ```
2. Modifiez le fichier pour introduire une erreur :
   ```bash
   echo "print('Erreur!')" > script.py
   git add script.py
   git commit -m "Introduction d'une erreur dans script.py"
   ```
3. Annulez le commit introduisant l'erreur :
   ```bash
   git revert HEAD
   ```

## Partie-03 Sécurité des données sensibles

Le versioning des données sensibles, telles que les clés d'API, les informations d'identification et les configurations de sécurité, est tout aussi crucial que celui du code. En maintenant un historique des changements apportés à ces données, les équipes peuvent identifier les accès non autorisés, les modifications malveillantes ou les erreurs de configuration qui pourraient compromettre la sécurité du système.

### Exemple de code

```bash
# Stocker des secrets dans AWS Secrets Manager
aws secretsmanager create-secret --name MySecret --secret-string "password123"

# Récupérer un secret
aws secretsmanager get-secret-value --secret-id MySecret
```

### Explication détaillée

1. **Stocker des secrets** : Utilise AWS Secrets Manager pour stocker un secret en toute sécurité.
2. **Récupérer un secret** : Récupère le secret stocké en utilisant son identifiant.

### Exemple de cas

En versionnant les configurations sensibles et en utilisant des outils de gestion de secrets, vous pouvez surveiller et contrôler l'accès à ces informations, réduisant ainsi les risques de compromission.

### Exercice

1. Créez un secret dans AWS Secrets Manager avec une clé et une valeur.
2. Récupérez ce secret en utilisant la CLI AWS.

**Corrigé de l'exercice :**

1. Créez un secret dans AWS Secrets Manager :
   ```bash
   aws secretsmanager create-secret --name MonSecret --secret-string "motdepasse123"
   ```
2. Récupérez le secret :
   ```bash
   aws secretsmanager get-secret-value --secret-id MonSecret
   ```

## Partie-04 Intégration avec les outils de déploiement

Les outils de déploiement tels que AWS CodeDeploy et AWS CodePipeline sont conçus pour fonctionner en étroite collaboration avec les systèmes de versioning. En intégrant le versioning du code dans ces pipelines de déploiement, les équipes peuvent automatiser efficacement le processus de mise à jour des applications en production tout en maintenant un contrôle strict sur les versions déployées.

### Exemple de code

```yaml
# Exemple de fichier de pipeline CodePipeline
pipeline:
  name: MyPipeline
  stages:
    - name: Source
      actions:
        - name: SourceAction
          actionTypeId:
            category: Source
            owner: AWS
            provider: CodeCommit
            version: 1
          outputArtifacts:
            - name: SourceArtifact
          configuration:
            RepositoryName: MyRepo
            BranchName: master
    - name: Deploy
      actions:
        - name: DeployAction
          actionTypeId:
            category: Deploy
            owner: AWS
            provider: CodeDeploy
            version: 1
          inputArtifacts:
            - name: SourceArtifact
          configuration:
            ApplicationName: MyApp
            DeploymentGroupName: MyDeploymentGroup
```

### Explication détaillée

1. **Source** : Définit la source du code à partir d'un dépôt CodeCommit.
2. **Deploy** : Définit l'étape de déploiement utilisant CodeDeploy pour déployer l'application.

### Exemple de cas

L'intégration du versioning dans le pipeline de déploiement assure que chaque déploiement est traçable et reproductible, ce qui est crucial pour les mises à jour fréquentes et les environnements de production.

### Exercice

1. Créez un dépôt CodeCommit.
2. Configurez un pipeline CodePipeline pour déployer le code à partir de ce dépôt en utilisant CodeDeploy.

**Corrigé de l'exercice :**

1. Créez un dépôt CodeCommit :
   ```bash
   aws codecommit create-repository --repository-name MonRepo
   ```
2. Configurez un pipeline CodePipeline :
   ```yaml
   pipeline:
     name: MonPipeline
     stages:
       - name: Source
         actions:
           - name: SourceAction
             actionTypeId:
               category: Source
               owner: AWS
               provider: CodeCommit
               version: 1
             outputArtifacts:
               - name: SourceArtifact
             configuration:
               RepositoryName: MonRepo
               BranchName: master
       - name: Deploy
         actions:
           - name: DeployAction
             actionTypeId:
               category: Deploy
               owner: AWS
               provider: CodeDeploy
               version: 1
             inputArtifacts:
               - name: SourceArtifact
             configuration:
               ApplicationName: MonApp
               DeploymentGroupName: MonGroupeDeDéploiement
   ```

## Partie-05 Meilleures pratiques de versioning

Pour tirer le meilleur parti du versioning, il est essentiel de suivre certaines meilleures pratiques. Cela inclut l'utilisation de systèmes de gestion de versions tels que Git, la documentation détaillée des changements apportés à chaque version, et la mise en place de politiques de contrôle d

'accès pour garantir la sécurité des données versionnées.

### Exemple de code

```bash
# Cloner un dépôt Git
git clone https://github.com/user/repo.git

# Créer une branche pour une nouvelle fonctionnalité
git checkout -b new-feature

# Fusionner la branche dans master après validation
git checkout master
git merge new-feature

# Pousser les changements vers le dépôt distant
git push origin master
```

### Explication détaillée

1. **Cloner un dépôt** : Crée une copie locale d'un dépôt Git distant.
2. **Créer une branche** : Crée une nouvelle branche pour développer une nouvelle fonctionnalité sans affecter la branche principale.
3. **Fusionner la branche** : Intègre les changements de la nouvelle branche dans la branche principale après validation.
4. **Pousser les changements** : Met à jour le dépôt distant avec les derniers changements.

### Exemple de cas

En suivant ces pratiques, les équipes peuvent travailler de manière collaborative et structurée, ce qui facilite la gestion des modifications et améliore la qualité du code.

### Exercice

1. Clonez un dépôt Git existant.
2. Créez une nouvelle branche pour une fonctionnalité.
3. Apportez des modifications et commitez-les.
4. Fusionnez la branche dans la branche principale et poussez les changements vers le dépôt distant.

**Corrigé de l'exercice :**

1. Clonez un dépôt Git :
   ```bash
   git clone https://github.com/utilisateur/repo.git
   ```
2. Créez une nouvelle branche pour une fonctionnalité :
   ```bash
   git checkout -b nouvelle-fonctionnalité
   ```
3. Apportez des modifications et commitez-les :
   ```bash
   echo "print('Nouvelle fonctionnalité')" > nouveau_script.py
   git add nouveau_script.py
   git commit -m "Ajout d'une nouvelle fonctionnalité"
   ```
4. Fusionnez la branche dans la branche principale et poussez les changements :
   ```bash
   git checkout master
   git merge nouvelle-fonctionnalité
   git push origin master
   ```

---

# Chapitre-04 Utiliser des secrets et des variables environnementales

## Partie-01 Gestion des secrets

Les secrets sont des informations sensibles qui ne doivent pas être exposées dans le code source ou stockées dans des fichiers non sécurisés. Nous aborderons les meilleures pratiques pour la gestion des secrets, notamment l'utilisation de services de gestion des secrets tels que AWS Secrets Manager ou AWS Systems Manager Parameter Store.

### Exemple de code

```python
import boto3
from botocore.exceptions import NoCredentialsError, PartialCredentialsError

def get_secret():
    secret_name = "my_secret"
    region_name = "us-west-2"

    # Crée une session avec Boto3
    session = boto3.session.Session()
    client = session.client(
        service_name="secretsmanager",
        region_name=region_name
    )

    try:
        get_secret_value_response = client.get_secret_value(SecretId=secret_name)
        secret = get_secret_value_response["SecretString"]
        return secret

    except NoCredentialsError:
        print("No credentials provided")
    except PartialCredentialsError:
        print("Incomplete credentials provided")

# Utiliser le secret
my_secret = get_secret()
print(my_secret)
```

### Explication détaillée

1. **Boto3** : La bibliothèque AWS SDK pour Python qui permet d'interagir avec les services AWS.
2. **get_secret** : Fonction pour récupérer un secret stocké dans AWS Secrets Manager.

### Exemple de cas

Stocker des mots de passe, des clés d'API et d'autres informations sensibles dans AWS Secrets Manager au lieu de les inclure directement dans le code source.

### Exercice

1. Créez un secret dans AWS Secrets Manager.
2. Écrivez un script Python pour récupérer et afficher ce secret.

**Corrigé de l'exercice :**

1. Créez un secret dans AWS Secrets Manager :
   ```bash
   aws secretsmanager create-secret --name MonSecret --secret-string "motdepasse123"
   ```
2. Écrivez un script Python pour récupérer et afficher ce secret :
   ```python
   import boto3
   from botocore.exceptions import NoCredentialsError, PartialCredentialsError

   def get_secret():
       secret_name = "MonSecret"
       region_name = "us-west-2"

       session = boto3.session.Session()
       client = session.client(
           service_name="secretsmanager",
           region_name=region_name
       )

       try:
           get_secret_value_response = client.get_secret_value(SecretId=secret_name)
           secret = get_secret_value_response["SecretString"]
           return secret

       except NoCredentialsError:
           print("No credentials provided")
       except PartialCredentialsError:
           print("Incomplete credentials provided")

   # Utiliser le secret
   mon_secret = get_secret()
   print(mon_secret)
   ```

## Partie-02 Utilisation des variables environnementales

Les variables environnementales fournissent un moyen flexible de passer des informations de configuration à une application sans les durcir dans le code.

### Exemple de code

```python
import os

# Définir une variable environnementale
os.environ['DATABASE_URL'] = 'postgresql://user:password@localhost/dbname'

# Utiliser la variable environnementale
database_url = os.getenv('DATABASE_URL')
print(f"Database URL: {database_url}")
```

### Explication détaillée

1. **os.environ** : Utilisé pour définir une variable environnementale.
2. **os.getenv** : Utilisé pour récupérer la valeur d'une variable environnementale.

### Exemple de cas

Les variables environnementales permettent de configurer des applications déployées sur différents environnements (développement, test, production) sans modifier le code.

### Exercice

1. Définissez une variable environnementale dans votre terminal.
2. Écrivez un script Python pour lire et afficher cette variable.

**Corrigé de l'exercice :**

1. Définissez une variable environnementale dans votre terminal :
   ```bash
   export DATABASE_URL=postgresql://user:password@localhost/dbname
   ```
2. Écrivez un script Python pour lire et afficher cette variable :
   ```python
   import os

   database_url = os.getenv('DATABASE_URL')
   print(f"Database URL: {database_url}")
   ```

## Partie-03 Intégration avec les outils de gestion des secrets

Nous explorerons comment intégrer la gestion des secrets dans les pipelines de déploiement à l'aide d'outils tels que AWS CodePipeline et AWS CodeBuild.

### Exemple de code

```yaml
# Exemple de configuration pour AWS CodeBuild
version: 0.2

env:
  secrets-manager:
    MY_SECRET: my_secret

phases:
  build:
    commands:
      - echo "Le secret est $MY_SECRET"
```

### Explication détaillée

1. **secrets-manager** : Section pour définir les secrets à utiliser dans l'environnement de build.
2. **commands** : Commandes à exécuter pendant la phase de build, utilisant le secret récupéré.

### Exemple de cas

Automatiser la récupération de secrets lors du déploiement d'une application pour s'assurer que les informations sensibles sont disponibles au moment opportun sans compromettre leur sécurité.

### Exercice

1. Créez un pipeline CodePipeline avec une étape CodeBuild.
2. Configurez le pipeline pour récupérer un secret depuis AWS Secrets Manager et l'utiliser dans une étape de build.

**Corrigé de l'exercice :**

1. Créez un pipeline CodePipeline avec une étape CodeBuild :
   ```yaml
   version: 0.2

   env:
     secrets-manager:
       MON_SECRET: mon_secret

   phases:
     build:
       commands:
         - echo "Le secret est $MON_SECRET"
   ```
2. Configurez le pipeline pour récupérer un secret depuis AWS Secrets Manager :
   ```bash
   aws codepipeline create-pipeline --pipeline <nom_de_pipeline>
   ```

## Partie-04 Sécurisation des communications

Enfin, nous aborderons l'importance de sécuriser les communications entre les services et les applications lors de l'utilisation de secrets et de variables environnementales.

### Exemple de code

```python
import requests

# Envoyer une requête HTTPS sécurisée
response = requests.get('https://api.example.com/data', headers={'Authorization': 'Bearer my_token'})

# Vérifier la réponse
if response.status_code == 200:
    print("Requête réussie")
else:
    print("Échec de la requête")
```

### Explication détaillée

1. **requests** : Bibliothèque Python pour effectuer des requêtes HTTP.
2. **HTTPS** : Utilisation de HTTPS pour sécuriser la communication entre le client et le serveur.

### Exemple de cas

Utiliser HTTPS pour sécuriser les communications et protéger les données sensibles en transit, notamment lors de l'envoi de secrets ou de variables environnementales entre les services.

### Exercice

1. Écrivez un script Python pour envoyer une requête HTTPS à une API sécurisée.
2. Configurez l'authentification via un token récupéré depuis AWS Secrets Manager.

**Corrigé de l'exercice :**

1. Écrivez un script Python pour envoyer une requête HTTPS à une API sécurisée :
   ```python
   import requests
   import boto3

   def get_secret():
       secret_name = "mon_token"
       region_name = "us-west-2"

       session = boto3.session.Session()
       client = session.client(
           service_name="secretsmanager",
           region_name=region_name
       )

       get_secret_value_response = client.get_secret

_value(SecretId=secret_name)
       return get_secret_value_response["SecretString"]

   token = get_secret()

   response = requests.get('https://api.example.com/data', headers={'Authorization': f'Bearer {token}'})

   if response.status_code == 200:
       print("Requête réussie")
   else:
       print("Échec de la requête")
   ```

---

# Chapitre-05 Accéder à un serveur distant via le protocole SSH

## Partie-01 Configuration des instances EC2 sur AWS

Nous commencerons par examiner les étapes nécessaires pour configurer des instances EC2 sur AWS. Cela comprendra la création d'une instance EC2, la configuration des règles de sécurité du groupe de sécurité pour permettre l'accès SSH, et la récupération de la clé privée utilisée pour se connecter à l'instance.

### Exemple de code

```bash
# Lancer une instance EC2
aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro --key-name MyKeyPair --security-group-ids sg-0123456789abcdef0

# Décrire l'instance pour obtenir son adresse IP
aws ec2 describe-instances --instance-ids i-0123456789abcdef0
```

### Explication détaillée

1. **run-instances** : Commande pour lancer une nouvelle instance EC2.
2. **describe-instances** : Commande pour obtenir des informations sur une instance EC2, y compris son adresse IP publique.

### Exemple de cas

Lancer et configurer une instance EC2 pour héberger une application web et permettre l'accès SSH sécurisé pour la gestion et la maintenance.

### Exercice

1. Lancez une instance EC2 en utilisant la CLI AWS.
2. Récupérez l'adresse IP de l'instance.

**Corrigé de l'exercice :**

1. Lancez une instance EC2 :
   ```bash
   aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro --key-name MonCle --security-group-ids sg-0123456789abcdef0
   ```
2. Récupérez l'adresse IP de l'instance :
   ```bash
   aws ec2 describe-instances --instance-ids i-0123456789abcdef0 --query 'Reservations[0].Instances[0].PublicIpAddress'
   ```

## Partie-02 Installation et configuration de PuTTY

Nous explorerons ensuite comment installer et configurer PuTTY, un client SSH largement utilisé pour se connecter à des serveurs distants.

### Instructions

1. **Téléchargez PuTTY** : Allez sur le site officiel de PuTTY et téléchargez l'installateur approprié pour votre système d'exploitation.
2. **Installez PuTTY** : Suivez les instructions d'installation pour installer PuTTY sur votre machine.
3. **Importez la clé privée AWS dans PuTTY** : Utilisez `PuTTYgen` pour convertir votre clé privée AWS au format PuTTY (.ppk).

### Exemple de cas

Utiliser PuTTY pour se connecter à une instance EC2 en toute sécurité à des fins de gestion et de maintenance.

### Exercice

1. Installez PuTTY sur votre machine.
2. Importez une clé privée AWS et configurez une connexion SSH vers une instance EC2.

**Corrigé de l'exercice :**

1. Téléchargez et installez PuTTY à partir du [site officiel](https://www.putty.org/).
2. Ouvrez PuTTYgen, chargez votre clé privée AWS (.pem), puis sauvegardez la clé en tant que fichier .ppk.
3. Configurez une connexion SSH dans PuTTY en utilisant l'adresse IP de votre instance EC2 et le fichier de clé .ppk.

## Partie-03 Établissement de la connexion SSH

Dans cette partie, nous passerons en revue les étapes pour établir une connexion SSH sécurisée à l'instance EC2 à l'aide de PuTTY.

### Instructions

1. **Ouvrez PuTTY** : Lancez PuTTY sur votre machine.
2. **Configurez la session** : Entrez l'adresse IP de votre instance EC2 dans le champ "Host Name".
3. **Ajoutez la clé privée** : Dans la section "SSH" -> "Auth", parcourez et sélectionnez votre fichier de clé privée (.ppk).
4. **Établissez la connexion** : Cliquez sur "Open" pour ouvrir la connexion SSH à l'instance EC2.

### Exemple de cas

Gérer et maintenir une instance EC2 en utilisant une connexion SSH sécurisée pour exécuter des commandes à distance.

### Exercice

1. Configurez une connexion SSH à une instance EC2 en utilisant PuTTY.
2. Établissez la connexion et exécutez quelques commandes de base pour vérifier la connectivité.

**Corrigé de l'exercice :**

1. Ouvrez PuTTY et configurez la session avec l'adresse IP de votre instance EC2.
2. Dans la section "SSH" -> "Auth", sélectionnez votre fichier de clé privée (.ppk).
3. Cliquez sur "Open" pour ouvrir la connexion SSH.
4. Connectez-vous et exécutez des commandes de base comme `ls` ou `uname -a`.

## Partie-04 Gestion des clés SSH sur AWS

Nous discuterons également des meilleures pratiques pour la gestion des clés SSH sur AWS, y compris la rotation régulière des clés, la désactivation des clés non utilisées, et la configuration de règles de sécurité pour limiter l'accès aux adresses IP autorisées.

### Exemple de code

```bash
# Générer une nouvelle paire de clés SSH
ssh-keygen -t rsa -b 2048 -f my_new_key

# Importer la clé publique dans AWS
aws ec2 import-key-pair --key-name MyNewKeyPair --public-key-material file://my_new_key.pub

# Associer la nouvelle clé à une instance EC2
aws ec2 create-tags --resources i-0123456789abcdef0 --tags Key=Name,Value=MyNewKeyPair
```

### Explication détaillée

1. **ssh-keygen** : Génère une nouvelle paire de clés SSH.
2. **import-key-pair** : Importe la clé publique dans AWS pour une utilisation avec les instances EC2.
3. **create-tags** : Associe la nouvelle clé à une instance EC2 pour identifier la clé utilisée.

### Exemple de cas

Assurer la sécurité des accès SSH en utilisant des clés SSH correctement gérées et en suivant les meilleures pratiques de rotation et de désactivation des clés.

### Exercice

1. Générez une nouvelle paire de clés SSH.
2. Importez la clé publique dans AWS et associez-la à une instance EC2.

**Corrigé de l'exercice :**

1. Générez une nouvelle paire de clés SSH :
   ```bash
   ssh-keygen -t rsa -b 2048 -f ma_nouvelle_cle
   ```
2. Importez la clé publique dans AWS :
   ```bash
   aws ec2 import-key-pair --key-name MaNouvelleCle --public-key-material file://ma_nouvelle_cle.pub
   ```
3. Associez la clé à une instance EC2 :
   ```bash
   aws ec2 create-tags --resources i-0123456789abcdef0 --tags Key=Name,Value=MaNouvelleCle
   ```

---

# Module-03 Utiliser un service de Cloud Computing (EC2) pour déployer des scripts

## Chapitre-01 Déploiement de scripts sur EC2

Nous commencerons par comprendre les bases du déploiement de scripts sur des instances EC2. Cela inclura la création et la configuration d'une instance EC2, le transfert des scripts sur l'instance, et l'exécution des scripts à distance à l'aide de connexions SSH.

### Exemple de code

```bash
# Transférer un script sur l'instance EC2
scp -i my_key.pem my_script.sh ec2-user@<EC2_IP>:/home/ec2-user/

# Exécuter le script sur l'instance EC2
ssh -i my_key.pem ec2-user@<EC2_IP> 'bash /home/ec2-user/my_script.sh'
```

### Explication détaillée

1. **scp** : Commande pour copier des fichiers de manière sécurisée vers une instance EC2.
2. **ssh** : Commande pour se connecter de manière sécurisée à une instance EC2 et exécuter des commandes à distance.

### Exemple de cas

Déployer et exécuter un script de démarrage sur une instance EC2 pour configurer des applications ou des environnements.

### Exercice

1. Créez un script shell simple.
2. Transférez le script sur une instance EC2 et exécutez-le.

**Corrigé de l'exercice :**

1. Créez un script shell simple :
   ```bash
   echo "#!/bin/bash" > my_script.sh
   echo "echo Hello, World!" >> my_script.sh
   chmod +x my_script.sh
   ```
2. Transférez le script sur une instance EC2 et exécutez-le :
   ```bash
   scp -i ma_cle.pem my_script.sh ec2-user@<EC2_IP>:/home/ec2-user/
   ssh -i ma_cle.pem ec2-user@<EC2_IP> 'bash /home/ec2-user/my_script.sh'
   ```

## Chapitre-02 Automatisation des tâches avec des scripts sur EC2

Dans cette partie, nous explorerons comment automatiser

 des tâches récurrentes en exécutant des scripts sur des instances EC2. Nous aborderons des cas d'utilisation pratiques tels que la sauvegarde de données, la gestion des journaux, et la planification des tâches à l'aide de cron jobs.

### Exemple de code

```bash
# Éditer le crontab pour ajouter une tâche planifiée
crontab -e

# Ajouter une tâche cron pour exécuter un script tous les jours à minuit
0 0 * * * /home/ec2-user/my_script.sh
```

### Explication détaillée

1. **crontab** : Ouvre l'éditeur de crontab pour ajouter, supprimer ou modifier des tâches planifiées.
2. **tâche cron** : Définition d'une tâche planifiée pour exécuter un script à une heure spécifique.

### Exemple de cas

Automatiser des tâches de maintenance, telles que la sauvegarde de bases de données ou la rotation des journaux, en utilisant des scripts et cron jobs sur une instance EC2.

### Exercice

1. Configurez une tâche cron pour exécuter un script shell sur une instance EC2 à une heure spécifique.
2. Vérifiez que la tâche cron s'exécute correctement.

**Corrigé de l'exercice :**

1. Éditez le crontab pour ajouter une tâche planifiée :
   ```bash
   crontab -e
   ```
   Ajoutez la ligne suivante pour exécuter le script tous les jours à minuit :
   ```bash
   0 0 * * * /home/ec2-user/my_script.sh
   ```
2. Vérifiez que la tâche cron s'exécute correctement en vérifiant les logs ou en ajoutant des commandes de vérification dans le script.

## Chapitre-03 Surveillance et gestion des instances EC2

Nous discuterons également des meilleures pratiques pour surveiller et gérer les instances EC2 déployées pour l'exécution de scripts. Cela comprendra la configuration d'alertes CloudWatch pour surveiller les performances et l'utilisation des instances, ainsi que la mise en place de politiques de sauvegarde et de restauration pour garantir la disponibilité des données.

### Exemple de code

```bash
# Créer une alerte CloudWatch pour surveiller l'utilisation du CPU
aws cloudwatch put-metric-alarm --alarm-name HighCPUUtilization --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanOrEqualToThreshold --dimensions Name=InstanceId,Value=i-0123456789abcdef0 --evaluation-periods 1 --alarm-actions arn:aws:sns:us-west-2:123456789012:MyTopic
```

### Explication détaillée

1. **put-metric-alarm** : Crée une alarme CloudWatch pour surveiller une métrique spécifique.
2. **HighCPUUtilization** : Nom de l'alarme pour indiquer une utilisation élevée du CPU.

### Exemple de cas

Surveiller les performances des instances EC2 et recevoir des notifications en cas de dépassement de seuils critiques, permettant une réaction rapide pour maintenir la disponibilité et la performance des services.

### Exercice

1. Créez une alarme CloudWatch pour surveiller une métrique spécifique sur une instance EC2.
2. Configurez une action pour recevoir une notification en cas de dépassement du seuil.

**Corrigé de l'exercice :**

1. Créez une alarme CloudWatch :
   ```bash
   aws cloudwatch put-metric-alarm --alarm-name UtilisationCPUHaute --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanOrEqualToThreshold --dimensions Name=InstanceId,Value=i-0123456789abcdef0 --evaluation-periods 1 --alarm-actions arn:aws:sns:us-west-2:123456789012:MonTopic
   ```
2. Configurez une action pour recevoir une notification :
   ```bash
   aws sns create-topic --name MonTopic
   aws sns subscribe --topic-arn arn:aws:sns:us-west-2:123456789012:MonTopic --protocol email --notification-endpoint mon_email@example.com
   ```

---

# Utilisation du protocole SMTP pour l'envoi de mails automatiques

## Chapitre-04 Configuration d'un serveur de messagerie

Nous commencerons par comprendre les bases de la configuration d'un serveur de messagerie compatible SMTP. Cela inclura la configuration des paramètres SMTP, tels que l'hôte SMTP, le port et les informations d'identification nécessaires pour l'authentification.

### Exemple de code

```python
import smtplib
from email.mime.text import MIMEText

# Configurer le serveur SMTP
smtp_server = "smtp.example.com"
smtp_port = 587
smtp_user = "user@example.com"
smtp_password = "password"

# Créer le message
msg = MIMEText("Ceci est un message de test.")
msg["Subject"] = "Test SMTP"
msg["From"] = smtp_user
msg["To"] = "recipient@example.com"

# Envoyer le message
with smtplib.SMTP(smtp_server, smtp_port) as server:
    server.starttls()
    server.login(smtp_user, smtp_password)
    server.sendmail(smtp_user, ["recipient@example.com"], msg.as_string())
```

### Explication détaillée

1. **smtplib** : Bibliothèque Python pour envoyer des e-mails via le protocole SMTP.
2. **MIMEText** : Classe pour créer des objets de type texte MIME pour les e-mails.
3. **starttls** : Initialise une connexion sécurisée via TLS.

### Exemple de cas

Configurer un serveur SMTP pour envoyer des e-mails automatiques à des fins de notifications, d'alertes ou de rapports périodiques.

### Exercice

1. Configurez les paramètres SMTP pour un serveur de messagerie de votre choix.
2. Écrivez un script Python pour envoyer un e-mail de test.

**Corrigé de l'exercice :**

1. Configurez les paramètres SMTP :
   ```python
   smtp_server = "smtp.monserveur.com"
   smtp_port = 587
   smtp_user = "utilisateur@monserveur.com"
   smtp_password = "monmotdepasse"
   ```
2. Écrivez un script Python pour envoyer un e-mail de test :
   ```python
   import smtplib
   from email.mime.text import MIMEText

   msg = MIMEText("Ceci est un message de test.")
   msg["Subject"] = "Test SMTP"
   msg["From"] = smtp_user
   msg["To"] = "destinataire@exemple.com"

   with smtplib.SMTP(smtp_server, smtp_port) as server:
       server.starttls()
       server.login(smtp_user, smtp_password)
       server.sendmail(smtp_user, ["destinataire@exemple.com"], msg.as_string())
   ```

## Chapitre-05 Envoi d'e-mails automatiques avec Python

Dans cette partie, nous explorerons comment utiliser des scripts Python pour envoyer des e-mails automatiques via le protocole SMTP.

### Exemple de code

```python
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

def send_email(subject, body, to_email):
    smtp_server = "smtp.example.com"
    smtp_port = 587
    smtp_user = "user@example.com"
    smtp_password = "password"

    msg = MIMEMultipart()
    msg["From"] = smtp_user
    msg["To"] = to_email
    msg["Subject"] = subject

    msg.attach(MIMEText(body, "plain"))

    with smtplib.SMTP(smtp_server, smtp_port) as server:
        server.starttls()
        server.login(smtp_user, smtp_password)
        server.sendmail(smtp_user, to_email, msg.as_string())

send_email("Test SMTP", "Ceci est un e-mail automatique", "recipient@example.com")
```

### Explication détaillée

1. **MIMEMultipart** : Classe pour créer des e-mails multipart, permettant d'ajouter des pièces jointes.
2. **send_email** : Fonction pour envoyer un e-mail avec un sujet et un corps de texte.

### Exemple de cas

Envoyer des notifications automatiques pour des événements spécifiques, tels que des alertes de surveillance ou des rapports de synthèse.

### Exercice

1. Écrivez une fonction Python pour envoyer un e-mail avec un sujet et un corps de texte personnalisés.
2. Utilisez cette fonction pour envoyer un e-mail de test.

**Corrigé de l'exercice :**

1. Écrivez une fonction Python :
   ```python
   def envoyer_email(sujet, corps, email_destinataire):
       smtp_server = "smtp.monserveur.com"
       smtp_port = 587
       smtp_user = "utilisateur@monserveur.com"
       smtp_password = "monmotdepasse"

       msg = MIMEMultipart()
       msg["From"] = smtp_user
       msg["To"] = email_destinataire
       msg["Subject"] = sujet

       msg.attach(MIMEText(corps, "plain"))

       with smtplib.SMTP(smtp_server, smtp_port) as server:
           server.starttls()
           server.login(smtp_user, smtp_password)
           server.sendmail(smtp_user, email_destinataire, msg.as_string())

   envoyer_email("Test SMTP", "Ceci est un e-mail automatique", "destinataire@exemple.com")
   ```

## Chapitre-06 Gestion de la

 sécurité et de la fiabilité

Nous discuterons également des meilleures pratiques pour garantir la sécurité et la fiabilité de l'envoi de mails automatiques.

### Exemple de code

```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import ssl

def send_secure_email(subject, body, to_email):
    smtp_server = "smtp.example.com"
    smtp_port = 465
    smtp_user = "user@example.com"
    smtp_password = "password"

    msg = MIMEMultipart()
    msg["From"] = smtp_user
    msg["To"] = to_email
    msg["Subject"] = subject

    msg.attach(MIMEText(body, "plain"))

    context = ssl.create_default_context()
    with smtplib.SMTP_SSL(smtp_server, smtp_port, context=context) as server:
        server.login(smtp_user, smtp_password)
        server.sendmail(smtp_user, to_email, msg.as_string())

send_secure_email("Test SMTP sécurisé", "Ceci est un e-mail automatique avec SSL", "recipient@example.com")
```

### Explication détaillée

1. **ssl.create_default_context** : Crée un contexte SSL sécurisé pour établir une connexion SMTP sécurisée.
2. **SMTP_SSL** : Utilise SSL pour établir une connexion sécurisée au serveur SMTP.

### Exemple de cas

Garantir la sécurité des communications en utilisant SSL/TLS pour l'envoi d'e-mails, et s'assurer que les informations d'identification et le contenu des e-mails sont protégés.

### Exercice

1. Modifiez la fonction d'envoi d'e-mails pour utiliser SSL/TLS.
2. Envoyez un e-mail de test en utilisant une connexion sécurisée.

**Corrigé de l'exercice :**

1. Modifiez la fonction d'envoi d'e-mails pour utiliser SSL/TLS :
   ```python
   import ssl

   def envoyer_email_securise(sujet, corps, email_destinataire):
       smtp_server = "smtp.monserveur.com"
       smtp_port = 465
       smtp_user = "utilisateur@monserveur.com"
       smtp_password = "monmotdepasse"

       msg = MIMEMultipart()
       msg["From"] = smtp_user
       msg["To"] = email_destinataire
       msg["Subject"] = sujet

       msg.attach(MIMEText(corps, "plain"))

       context = ssl.create_default_context()
       with smtplib.SMTP_SSL(smtp_server, smtp_port, context=context) as server:
           server.login(smtp_user, smtp_password)
           server.sendmail(smtp_user, email_destinataire, msg.as_string())

   envoyer_email_securise("Test SMTP sécurisé", "Ceci est un e-mail automatique avec SSL", "destinataire@exemple.com")
   ```

---

# Scraping et rapatriement de données via le protocole HTTP

## Chapitre-07 Scraping de données web

Nous commencerons par comprendre les bases du scraping de données web à l'aide de bibliothèques Python telles que Beautiful Soup et Scrapy. Nous verrons comment extraire des données structurées à partir de pages web en utilisant des requêtes HTTP et des expressions XPath.

### Exemple de code

```python
import requests
from bs4 import BeautifulSoup

# Envoyer une requête HTTP à la page web
response = requests.get('https://example.com')

# Parser le contenu HTML avec Beautiful Soup
soup = BeautifulSoup(response.content, 'html.parser')

# Extraire des données spécifiques
title = soup.find('h1').text
print(f"Title: {title}")
```

### Explication détaillée

1. **requests.get** : Envoie une requête HTTP GET à une URL spécifiée.
2. **BeautifulSoup** : Parse le contenu HTML pour permettre l'extraction des données.
3. **find** : Recherche un élément HTML spécifique par son tag.

### Exemple de cas

Extraire des données d'un site web pour les analyser ou les utiliser dans une application, comme la récupération de titres d'articles ou de prix de produits.

### Exercice

1. Envoyez une requête HTTP à une page web de votre choix.
2. Utilisez Beautiful Soup pour extraire et afficher des données spécifiques de la page.

**Corrigé de l'exercice :**

1. Envoyez une requête HTTP à une page web :
   ```python
   response = requests.get('https://exemple.com')
   ```
2. Utilisez Beautiful Soup pour extraire et afficher des données spécifiques :
   ```python
   soup = BeautifulSoup(response.content, 'html.parser')
   titre = soup.find('h1').text
   print(f"Titre : {titre}")
   ```

## Chapitre-08 Rapatriement de données via le protocole HTTP

Dans cette partie, nous explorerons comment rapatrier des données à partir de services web externes via le protocole HTTP. Cela inclura la configuration des requêtes HTTP, le traitement des réponses JSON ou XML, et la gestion des erreurs de communication avec les services web.

### Exemple de code

```python
import requests

# Envoyer une requête GET à une API et récupérer la réponse en JSON
response = requests.get('https://api.example.com/data')

if response.status_code == 200:
    data = response.json()
    print(data)
else:
    print("Erreur lors de la récupération des données")
```

### Explication détaillée

1. **requests.get** : Envoie une requête HTTP GET à une URL spécifiée.
2. **response.json** : Convertit la réponse en format JSON en un dictionnaire Python.

### Exemple de cas

Rapatrier des données à partir d'une API pour les utiliser dans une application, comme la récupération de données météorologiques ou financières.

### Exercice

1. Envoyez une requête HTTP à une API de votre choix.
2. Récupérez et affichez les données renvoyées en format JSON.

**Corrigé de l'exercice :**

1. Envoyez une requête HTTP à une API :
   ```python
   response = requests.get('https://api.exemple.com/donnees')
   ```
2. Récupérez et affichez les données en format JSON :
   ```python
   if response.status_code == 200:
       data = response.json()
       print(data)
   else:
       print("Erreur lors de la récupération des données")
   ```

## Chapitre-09 Utilisation avancée du scraping et du rapatriement de données

Nous discuterons également des meilleures pratiques pour le scraping et le rapatriement de données, y compris la mise en cache des données, la limitation des requêtes pour éviter le blocage, et la gestion des données extraites ou rapatriées pour assurer leur qualité et leur intégrité.

### Exemple de code

```python
import requests
from cachecontrol import CacheControl

# Utiliser CacheControl pour mettre en cache les requêtes HTTP
session = CacheControl(requests.Session())

# Envoyer une requête avec mise en cache
response = session.get('https://api.example.com/data')

if response.status_code == 200:
    data = response.json()
    print(data)
else:
    print("Erreur lors de la récupération des données")
```

### Explication détaillée

1. **CacheControl** : Bibliothèque pour ajouter une couche de mise en cache aux requêtes HTTP.
2. **requests.Session** : Gère une session de requêtes HTTP avec mise en cache.

### Exemple de cas

Améliorer l'efficacité et réduire la charge sur les serveurs en mettant en cache les réponses des requêtes HTTP fréquentes et en gérant les limites de taux pour éviter les blocages.

### Exercice

1. Configurez une session de requêtes HTTP avec CacheControl pour mettre en cache les réponses.
2. Envoyez une requête HTTP et vérifiez que les données sont mises en cache.

**Corrigé de l'exercice :**

1. Configurez une session de requêtes HTTP avec CacheControl :
   ```python
   from cachecontrol import CacheControl
   session = CacheControl(requests.Session())
   ```
2. Envoyez une requête HTTP et vérifiez que les données sont mises en cache :
   ```python
   response = session.get('https://api.exemple.com/donnees')

   if response.status_code == 200:
       data = response.json()
       print(data)
   else:
       print("Erreur lors de la récupération des données")
   ```

---
MODULE-04 : Utiliser un service de Cloud Computing (EC2) pour déployer une base
données
# Module-04 : Utiliser un service de Cloud Computing (EC2) pour déployer une base de données

**Provider utilisé : Amazon Web Services (AWS)**

## Chapitre-01 Configuration de l'environnement AWS

### Partie-01 Création d'un compte AWS

Pour commencer à utiliser les services AWS, vous devez créer un compte AWS.

### Étape 1 : Inscription à AWS
1. Allez sur [aws.amazon.com](https://aws.amazon.com).
2. Cliquez sur "Créer un compte AWS".
3. Suivez les instructions pour créer votre compte.

### Étape 2 : Configuration de la facturation
1. Connectez-vous à votre compte AWS.
2. Allez dans la section "Billing and Cost Management" pour configurer vos informations de paiement.

### Exercice
1. Créez un compte AWS en suivant les étapes ci-dessus.
2. Configurez les informations de facturation.

**Corrigé de l'exercice :**
1. Suivez les instructions sur [aws.amazon.com](https://aws.amazon.com) pour créer un compte.
2. Une fois connecté, configurez vos informations de facturation sous "Billing and Cost Management".

### Partie-02 Installation et configuration de la CLI AWS

La CLI AWS vous permet d'interagir avec les services AWS à partir de la ligne de commande.

### Étape 1 : Installation de la CLI AWS
1. Téléchargez l'installateur de la CLI AWS à partir de [AWS CLI](https://aws.amazon.com/cli/).
2. Suivez les instructions d'installation pour votre système d'exploitation.

### Étape 2 : Configuration de la CLI AWS
1. Ouvrez votre terminal ou invite de commandes.
2. Exécutez `aws configure` et entrez vos informations d'identification AWS :
   ```bash
   aws configure
   ```
3. Entrez les valeurs suivantes :
   - AWS Access Key ID
   - AWS Secret Access Key
   - Default region name (par exemple, us-west-2)
   - Default output format (json)

### Exercice
1. Installez la CLI AWS.
2. Configurez la CLI AWS en utilisant vos informations d'identification.

**Corrigé de l'exercice :**
1. Téléchargez et installez la CLI AWS à partir de [AWS CLI](https://aws.amazon.com/cli/).
2. Ouvrez votre terminal et exécutez `aws configure`, puis entrez vos informations d'identification AWS.

## Chapitre-02 Lancement d'une instance EC2

### Partie-01 Création et configuration d'une instance EC2

### Étape 1 : Lancer une instance EC2
1. Connectez-vous à la console AWS.
2. Allez dans "Services" et sélectionnez "EC2".
3. Cliquez sur "Lancer une instance".
4. Suivez les étapes pour configurer votre instance :
   - Choisissez une AMI (Amazon Machine Image).
   - Sélectionnez un type d'instance (par exemple, t2.micro).
   - Configurez les détails de l'instance.
   - Ajoutez du stockage.
   - Configurez les groupes de sécurité.

### Étape 2 : Configuration des groupes de sécurité
1. Créez un nouveau groupe de sécurité ou utilisez un groupe existant.
2. Ajoutez des règles pour autoriser le trafic SSH (port 22) et le trafic de la base de données (par exemple, MySQL sur le port 3306).

### Exercice
1. Lancez une instance EC2 en suivant les étapes ci-dessus.
2. Configurez un groupe de sécurité pour autoriser le trafic SSH et le trafic de la base de données.

**Corrigé de l'exercice :**
1. Suivez les étapes dans la console AWS pour lancer une instance EC2.
2. Créez un groupe de sécurité avec les règles suivantes :
   - SSH : TCP, Port 22, Source : 0.0.0.0/0 (ou restreignez l'accès à votre IP)
   - MySQL/Aurora : TCP, Port 3306, Source : 0.0.0.0/0 (ou restreignez l'accès à votre IP)

### Partie-02 Connexion à l'instance EC2

### Étape 1 : Utilisation de SSH pour se connecter
1. Téléchargez le fichier .pem de votre clé privée si vous ne l'avez pas déjà.
2. Modifiez les permissions de la clé pour qu'elle soit sécurisée :
   ```bash
   chmod 400 your-key.pem
   ```
3. Connectez-vous à l'instance EC2 en utilisant SSH :
   ```bash
   ssh -i your-key.pem ec2-user@your-ec2-ip
   ```

### Exercice
1. Téléchargez et sécurisez votre clé privée .pem.
2. Connectez-vous à votre instance EC2 en utilisant SSH.

**Corrigé de l'exercice :**
1. Téléchargez votre fichier .pem et exécutez :
   ```bash
   chmod 400 your-key.pem
   ```
2. Connectez-vous à l'instance EC2 :
   ```bash
   ssh -i your-key.pem ec2-user@your-ec2-ip
   ```

## Chapitre-03 Installation de MySQL sur EC2

### Partie-01 Installation de MySQL

### Étape 1 : Mise à jour des packages et installation de MySQL
1. Connectez-vous à votre instance EC2.
2. Mettez à jour les packages :
   ```bash
   sudo yum update -y
   ```
3. Installez MySQL :
   ```bash
   sudo yum install mysql-server -y
   ```

### Étape 2 : Démarrage du service MySQL
1. Démarrez MySQL :
   ```bash
   sudo service mysqld start
   ```
2. Configurez MySQL pour démarrer au boot :
   ```bash
   sudo chkconfig mysqld on
   ```

### Exercice
1. Installez MySQL sur votre instance EC2.
2. Démarrez le service MySQL et configurez-le pour démarrer au boot.

**Corrigé de l'exercice :**
1. Connectez-vous à votre instance EC2 et exécutez :
   ```bash
   sudo yum update -y
   sudo yum install mysql-server -y
   ```
2. Démarrez MySQL et configurez-le pour démarrer au boot :
   ```bash
   sudo service mysqld start
   sudo chkconfig mysqld on
   ```

### Partie-02 Configuration de MySQL

### Étape 1 : Configuration initiale de MySQL
1. Exécutez le script de sécurité initial :
   ```bash
   sudo mysql_secure_installation
   ```
2. Suivez les instructions pour sécuriser votre installation MySQL (définir un mot de passe root, supprimer les utilisateurs anonymes, désactiver les connexions root à distance, etc.).

### Étape 2 : Création d'une base de données et d'un utilisateur
1. Connectez-vous à MySQL en tant que root :
   ```bash
   mysql -u root -p
   ```
2. Créez une nouvelle base de données :
   ```sql
   CREATE DATABASE ma_base_de_donnees;
   ```
3. Créez un nouvel utilisateur et accordez-lui les privilèges :
   ```sql
   CREATE USER 'mon_utilisateur'@'%' IDENTIFIED BY 'mon_mot_de_passe';
   GRANT ALL PRIVILEGES ON ma_base_de_donnees.* TO 'mon_utilisateur'@'%';
   FLUSH PRIVILEGES;
   ```

### Exercice
1. Exécutez le script de sécurité initial de MySQL.
2. Créez une nouvelle base de données et un utilisateur avec les privilèges appropriés.

**Corrigé de l'exercice :**
1. Exécutez :
   ```bash
   sudo mysql_secure_installation
   ```
2. Connectez-vous à MySQL et créez une base de données et un utilisateur :
   ```sql
   mysql -u root -p
   CREATE DATABASE ma_base_de_donnees;
   CREATE USER 'mon_utilisateur'@'%' IDENTIFIED BY 'mon_mot_de_passe';
   GRANT ALL PRIVILEGES ON ma_base_de_donnees.* TO 'mon_utilisateur'@'%';
   FLUSH PRIVILEGES;
   ```

## Chapitre-04 Sécurisation et accès à distance

### Partie-01 Configuration du pare-feu et du groupe de sécurité

### Étape 1 : Configuration du pare-feu
1. Ouvrez le port MySQL dans le pare-feu :
   ```bash
   sudo iptables -A INPUT -p tcp --dport 3306 -j ACCEPT
   sudo service iptables save
   ```

### Étape 2 : Configuration du groupe de sécurité
1. Allez dans la console AWS.
2. Sélectionnez votre groupe de sécurité et ajoutez une règle pour autoriser le trafic entrant sur le port 3306 depuis votre IP ou votre plage d'IP.

### Exercice
1. Ouvrez le port MySQL dans le pare-feu de votre instance EC2.
2. Configurez votre groupe de sécurité pour autoriser le trafic entrant sur le port 3306.

**Corrigé de l'exercice :**
1. Ouvrez le port MySQL dans le pare-feu :
   ```bash
   sudo iptables -A INPUT -p tcp --dport 3306 -j ACCEPT
   sudo

 service iptables save
   ```
2. Dans la console AWS, ajoutez une règle de groupe de sécurité pour le port 3306.

### Partie-02 Configuration de MySQL pour l'accès à distance

### Étape 1 : Modifier le fichier de configuration de MySQL
1. Ouvrez le fichier de configuration de MySQL :
   ```bash
   sudo vi /etc/my.cnf
   ```
2. Commentez ou modifiez la ligne `bind-address` pour permettre l'accès à distance :
   ```bash
   #bind-address=127.0.0.1
   ```

### Étape 2 : Redémarrage de MySQL
1. Redémarrez le service MySQL pour appliquer les changements :
   ```bash
   sudo service mysqld restart
   ```

### Exercice
1. Modifiez le fichier de configuration de MySQL pour permettre l'accès à distance.
2. Redémarrez le service MySQL.

**Corrigé de l'exercice :**
1. Modifiez le fichier de configuration :
   ```bash
   sudo vi /etc/my.cnf
   #bind-address=127.0.0.1
   ```
2. Redémarrez MySQL :
   ```bash
   sudo service mysqld restart
   ```

## Chapitre-05 Surveillance et sauvegarde de la base de données

### Partie-01 Surveillance de la base de données avec CloudWatch

### Étape 1 : Activer les métriques CloudWatch pour EC2
1. Allez dans la console AWS.
2. Sélectionnez votre instance EC2.
3. Allez dans l'onglet "Monitoring" et activez les métriques CloudWatch.

### Étape 2 : Configuration des alarmes CloudWatch
1. Allez dans la console CloudWatch.
2. Créez une nouvelle alarme pour surveiller l'utilisation du CPU, la mémoire ou les E/S disque.

### Exercice
1. Activez les métriques CloudWatch pour votre instance EC2.
2. Configurez une alarme CloudWatch pour surveiller l'utilisation du CPU.

**Corrigé de l'exercice :**
1. Activez les métriques CloudWatch dans l'onglet "Monitoring" de votre instance EC2.
2. Créez une alarme CloudWatch pour l'utilisation du CPU.

### Partie-02 Sauvegarde et restauration de la base de données

### Étape 1 : Sauvegarde de la base de données
1. Utilisez `mysqldump` pour sauvegarder la base de données :
   ```bash
   mysqldump -u mon_utilisateur -p ma_base_de_donnees > sauvegarde.sql
   ```

### Étape 2 : Restauration de la base de données
1. Utilisez `mysql` pour restaurer la base de données :
   ```bash
   mysql -u mon_utilisateur -p ma_base_de_donnees < sauvegarde.sql
   ```

### Exercice
1. Effectuez une sauvegarde de votre base de données.
2. Restaurez la base de données à partir de la sauvegarde.

**Corrigé de l'exercice :**
1. Sauvegardez la base de données :
   ```bash
   mysqldump -u mon_utilisateur -p ma_base_de_donnees > sauvegarde.sql
   ```
2. Restaurez la base de données :
   ```bash
   mysql -u mon_utilisateur -p ma_base_de_donnees < sauvegarde.sql
   ```

---
# Module-05 : Utiliser un service de Cloud Computing (EC2) pour déployer une API

**Provider utilisé : Amazon Web Services (AWS)**

## Chapitre-01 Configuration de l'environnement AWS

### Partie-01 Création d'un compte AWS

Pour commencer à utiliser les services AWS, vous devez créer un compte AWS.

### Étape 1 : Inscription à AWS
1. Allez sur [aws.amazon.com](https://aws.amazon.com).
2. Cliquez sur "Créer un compte AWS".
3. Suivez les instructions pour créer votre compte.

### Étape 2 : Configuration de la facturation
1. Connectez-vous à votre compte AWS.
2. Allez dans la section "Billing and Cost Management" pour configurer vos informations de paiement.

### Exercice
1. Créez un compte AWS en suivant les étapes ci-dessus.
2. Configurez les informations de facturation.

**Corrigé de l'exercice :**
1. Suivez les instructions sur [aws.amazon.com](https://aws.amazon.com) pour créer un compte.
2. Une fois connecté, configurez vos informations de facturation sous "Billing and Cost Management".

### Partie-02 Installation et configuration de la CLI AWS

La CLI AWS vous permet d'interagir avec les services AWS à partir de la ligne de commande.

### Étape 1 : Installation de la CLI AWS
1. Téléchargez l'installateur de la CLI AWS à partir de [AWS CLI](https://aws.amazon.com/cli/).
2. Suivez les instructions d'installation pour votre système d'exploitation.

### Étape 2 : Configuration de la CLI AWS
1. Ouvrez votre terminal ou invite de commandes.
2. Exécutez `aws configure` et entrez vos informations d'identification AWS :
   ```bash
   aws configure
   ```
3. Entrez les valeurs suivantes :
   - AWS Access Key ID
   - AWS Secret Access Key
   - Default region name (par exemple, us-west-2)
   - Default output format (json)

### Exercice
1. Installez la CLI AWS.
2. Configurez la CLI AWS en utilisant vos informations d'identification.

**Corrigé de l'exercice :**
1. Téléchargez et installez la CLI AWS à partir de [AWS CLI](https://aws.amazon.com/cli/).
2. Ouvrez votre terminal et exécutez `aws configure`, puis entrez vos informations d'identification AWS.

## Chapitre-02 Lancement d'une instance EC2

### Partie-01 Création et configuration d'une instance EC2

### Étape 1 : Lancer une instance EC2
1. Connectez-vous à la console AWS.
2. Allez dans "Services" et sélectionnez "EC2".
3. Cliquez sur "Lancer une instance".
4. Suivez les étapes pour configurer votre instance :
   - Choisissez une AMI (Amazon Machine Image).
   - Sélectionnez un type d'instance (par exemple, t2.micro).
   - Configurez les détails de l'instance.
   - Ajoutez du stockage.
   - Configurez les groupes de sécurité.

### Étape 2 : Configuration des groupes de sécurité
1. Créez un nouveau groupe de sécurité ou utilisez un groupe existant.
2. Ajoutez des règles pour autoriser le trafic SSH (port 22), le trafic HTTP (port 80), et le trafic de l'API (par exemple, sur le port 8000).

### Exercice
1. Lancez une instance EC2 en suivant les étapes ci-dessus.
2. Configurez un groupe de sécurité pour autoriser le trafic SSH, HTTP, et le trafic de l'API.

**Corrigé de l'exercice :**
1. Suivez les étapes dans la console AWS pour lancer une instance EC2.
2. Créez un groupe de sécurité avec les règles suivantes :
   - SSH : TCP, Port 22, Source : 0.0.0.0/0 (ou restreignez l'accès à votre IP)
   - HTTP : TCP, Port 80, Source : 0.0.0.0/0
   - Custom TCP Rule : TCP, Port 8000, Source : 0.0.0.0/0

### Partie-02 Connexion à l'instance EC2

### Étape 1 : Utilisation de SSH pour se connecter
1. Téléchargez le fichier .pem de votre clé privée si vous ne l'avez pas déjà.
2. Modifiez les permissions de la clé pour qu'elle soit sécurisée :
   ```bash
   chmod 400 your-key.pem
   ```
3. Connectez-vous à l'instance EC2 en utilisant SSH :
   ```bash
   ssh -i your-key.pem ec2-user@your-ec2-ip
   ```

### Exercice
1. Téléchargez et sécurisez votre clé privée .pem.
2. Connectez-vous à votre instance EC2 en utilisant SSH.

**Corrigé de l'exercice :**
1. Téléchargez votre fichier .pem et exécutez :
   ```bash
   chmod 400 your-key.pem
   ```
2. Connectez-vous à l'instance EC2 :
   ```bash
   ssh -i your-key.pem ec2-user@your-ec2-ip
   ```

## Chapitre-03 Installation de FastAPI et des dépendances

### Partie-01 Installation de Python et FastAPI

### Étape 1 : Mise à jour des packages et installation de Python
1. Connectez-vous à votre instance EC2.
2. Mettez à jour les packages :
   ```bash
   sudo yum update -y
   ```
3. Installez Python 3 :
   ```bash
   sudo yum install python3 -y
   ```

### Étape 2 : Installation de FastAPI et Uvicorn
1. Installez FastAPI et Uvicorn :
   ```bash
   pip3 install fastapi uvicorn
   ```

### Exercice
1. Installez Python 3 sur votre instance EC2.
2. Installez FastAPI et Uvicorn.

**Corrigé de l'exercice :**
1. Connectez-vous à votre instance EC2 et exécutez :
   ```bash
   sudo yum update -y
   sudo yum install python3 -y
   ```
2. Installez FastAPI et Uvicorn :
   ```bash
   pip3 install fastapi uvicorn
   ```

### Partie-02 Création d'une application FastAPI simple

### Étape 1 : Création d'un fichier main.py
1. Créez un fichier `main.py` :
   ```python
   from fastapi import FastAPI

   app = FastAPI()

   @app.get("/")
   def read_root():
       return {"Hello": "World"}
   ```

### Étape 2 : Lancement de l'application FastAPI
1. Lancez l'application FastAPI avec Uvicorn :
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000
   ```

### Exercice
1. Créez un fichier `main.py` avec le code FastAPI ci-dessus.
2. Lancez l'application FastAPI sur votre instance EC2.

**Corrigé de l'exercice :**
1. Créez un fichier `main.py` :
   ```python
   from fastapi import FastAPI

   app = FastAPI()

   @app.get("/")
   def read_root():
       return {"Hello": "World"}
   ```
2. Lancez l'application FastAPI :
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000
   ```

## Chapitre-04 Connexion à une base de données SQL

### Partie-01 Installation et configuration de MySQL

### Étape 1 : Installation de MySQL
1. Connectez-vous à votre instance EC2.
2. Installez MySQL :
   ```bash
   sudo yum install mysql-server -y
   ```

### Étape 2 : Démarrage et sécurisation de MySQL
1. Démarrez MySQL :
   ```bash
   sudo service mysqld start
   ```
2. Configurez MySQL pour démarrer au boot :
   ```bash
   sudo chkconfig mysqld on
   ```
3. Exécutez le script de sécurité initial :
   ```bash
   sudo mysql_secure_installation
   ```

### Exercice
1. Installez MySQL sur votre instance EC2.
2. Démarrez et sécurisez MySQL.

**Corrigé de l'exercice :**
1. Connectez-vous à votre instance EC2 et exécutez :
   ```bash
   sudo yum install mysql-server -y
   sudo service mysqld start
   sudo chkconfig mysqld on
   sudo mysql_secure_installation
   ```

### Partie-02 Connexion de FastAPI à MySQL

### Étape 1 : Installation des dépendances MySQL pour Python
1. Installez le connecteur MySQL pour Python :
   ```bash
   pip3 install pymysql sqlalchemy
   ```

### Étape 2 : Configuration de la connexion dans FastAPI
1. Modifiez `main.py` pour inclure la connexion à la base de données :
   ```python
   from fastapi import FastAPI, Depends
   from sqlalchemy import create_engine
   from sqlalchemy.ext.declarative import declarative_base
   from sqlalchemy.orm import sessionmaker

   SQLALCHEMY_DATABASE_URL = "mysql+pymysql://

user:password@localhost/db_name"

   engine = create_engine(SQLALCHEMY_DATABASE_URL)
   SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
   Base = declarative_base()

   app = FastAPI()

   @app.get("/")
   def read_root():
       return {"Hello": "World"}

   @app.get("/items/")
   def read_items(db: Session = Depends(get_db)):
       items = db.execute("SELECT * FROM items").fetchall()
       return items

   def get_db():
       db = SessionLocal()
       try:
           yield db
       finally:
           db.close()
   ```

### Exercice
1. Installez les dépendances MySQL pour Python.
2. Modifiez `main.py` pour inclure la connexion à la base de données.

**Corrigé de l'exercice :**
1. Installez les dépendances MySQL :
   ```bash
   pip3 install pymysql sqlalchemy
   ```
2. Modifiez `main.py` :
   ```python
   from fastapi import FastAPI, Depends
   from sqlalchemy import create_engine
   from sqlalchemy.ext.declarative import declarative_base
   from sqlalchemy.orm import sessionmaker

   SQLALCHEMY_DATABASE_URL = "mysql+pymysql://user:password@localhost/db_name"

   engine = create_engine(SQLALCHEMY_DATABASE_URL)
   SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
   Base = declarative_base()

   app = FastAPI()

   @app.get("/")
   def read_root():
       return {"Hello": "World"}

   @app.get("/items/")
   def read_items(db: Session = Depends(get_db)):
       items = db.execute("SELECT * FROM items").fetchall()
       return items

   def get_db():
       db = SessionLocal()
       try:
           yield db
       finally:
           db.close()
   ```

## Chapitre-05 Déploiement de l'API sur EC2

### Partie-01 Configuration du déploiement avec Systemd

### Étape 1 : Création d'un service Systemd
1. Créez un fichier de service pour votre application FastAPI :
   ```bash
   sudo vi /etc/systemd/system/fastapi.service
   ```
2. Ajoutez le contenu suivant :
   ```ini
   [Unit]
   Description=FastAPI application
   After=network.target

   [Service]
   User=ec2-user
   Group=ec2-user
   WorkingDirectory=/home/ec2-user
   ExecStart=/usr/local/bin/uvicorn main:app --host 0.0.0.0 --port 8000

   [Install]
   WantedBy=multi-user.target
   ```

### Étape 2 : Démarrage et activation du service
1. Rechargez Systemd pour appliquer les modifications :
   ```bash
   sudo systemctl daemon-reload
   ```
2. Démarrez le service FastAPI :
   ```bash
   sudo systemctl start fastapi
   ```
3. Activez le service pour qu'il démarre au boot :
   ```bash
   sudo systemctl enable fastapi
   ```

### Exercice
1. Créez un fichier de service Systemd pour votre application FastAPI.
2. Démarrez et activez le service.

**Corrigé de l'exercice :**
1. Créez et éditez le fichier `/etc/systemd/system/fastapi.service` :
   ```ini
   [Unit]
   Description=FastAPI application
   After=network.target

   [Service]
   User=ec2-user
   Group=ec2-user
   WorkingDirectory=/home/ec2-user
   ExecStart=/usr/local/bin/uvicorn main:app --host 0.0.0.0 --port 8000

   [Install]
   WantedBy=multi-user.target
   ```
2. Rechargez Systemd, démarrez et activez le service :
   ```bash
   sudo systemctl daemon-reload
   sudo systemctl start fastapi
   sudo systemctl enable fastapi
   ```

### Partie-02 Vérification du déploiement

### Étape 1 : Tester l'API
1. Ouvrez un navigateur web ou utilisez `curl` pour accéder à votre API :
   ```bash
   curl http://your-ec2-ip:8000/
   ```

### Exercice
1. Testez votre API en accédant à l'endpoint racine.

**Corrigé de l'exercice :**
1. Testez l'API avec `curl` :
   ```bash
   curl http://your-ec2-ip:8000/
   ```

---

# Module-06 : Utiliser un service de Cloud Computing (Bucket S3) pour stocker des fichiers

**Provider utilisé : Amazon Web Services (AWS)**

## Chapitre-01 Configuration de l'environnement AWS

### Partie-01 Création d'un compte AWS

Pour commencer à utiliser les services AWS, vous devez créer un compte AWS.

### Étape 1 : Inscription à AWS
1. Allez sur [aws.amazon.com](https://aws.amazon.com).
2. Cliquez sur "Créer un compte AWS".
3. Suivez les instructions pour créer votre compte.

### Étape 2 : Configuration de la facturation
1. Connectez-vous à votre compte AWS.
2. Allez dans la section "Billing and Cost Management" pour configurer vos informations de paiement.

### Exercice
1. Créez un compte AWS en suivant les étapes ci-dessus.
2. Configurez les informations de facturation.

**Corrigé de l'exercice :**
1. Suivez les instructions sur [aws.amazon.com](https://aws.amazon.com) pour créer un compte.
2. Une fois connecté, configurez vos informations de facturation sous "Billing and Cost Management".

### Partie-02 Installation et configuration de la CLI AWS

La CLI AWS vous permet d'interagir avec les services AWS à partir de la ligne de commande.

### Étape 1 : Installation de la CLI AWS
1. Téléchargez l'installateur de la CLI AWS à partir de [AWS CLI](https://aws.amazon.com/cli/).
2. Suivez les instructions d'installation pour votre système d'exploitation.

### Étape 2 : Configuration de la CLI AWS
1. Ouvrez votre terminal ou invite de commandes.
2. Exécutez `aws configure` et entrez vos informations d'identification AWS :
   ```bash
   aws configure
   ```
3. Entrez les valeurs suivantes :
   - AWS Access Key ID
   - AWS Secret Access Key
   - Default region name (par exemple, us-west-2)
   - Default output format (json)

### Exercice
1. Installez la CLI AWS.
2. Configurez la CLI AWS en utilisant vos informations d'identification.

**Corrigé de l'exercice :**
1. Téléchargez et installez la CLI AWS à partir de [AWS CLI](https://aws.amazon.com/cli/).
2. Ouvrez votre terminal et exécutez `aws configure`, puis entrez vos informations d'identification AWS.

## Chapitre-02 Création et configuration d'un Bucket S3

### Partie-01 Création d'un Bucket S3

### Étape 1 : Créer un Bucket S3
1. Connectez-vous à la console AWS.
2. Allez dans "Services" et sélectionnez "S3".
3. Cliquez sur "Créer un Bucket".
4. Suivez les étapes pour configurer votre bucket :
   - Nommez votre bucket (nom unique).
   - Sélectionnez la région.
   - Configurez les options de propriété et de permissions (défaut).

### Étape 2 : Configuration des permissions du Bucket S3
1. Allez dans l'onglet "Permissions" de votre bucket S3.
2. Configurez les permissions pour autoriser les actions nécessaires (lecture, écriture).

### Exercice
1. Créez un Bucket S3 en suivant les étapes ci-dessus.
2. Configurez les permissions pour permettre l'accès requis.

**Corrigé de l'exercice :**
1. Suivez les étapes dans la console AWS pour créer un Bucket S3.
2. Configurez les permissions dans l'onglet "Permissions" pour autoriser les actions nécessaires.

### Partie-02 Configuration des politiques IAM

### Étape 1 : Créer une politique IAM pour S3
1. Allez dans "IAM" dans la console AWS.
2. Créez une nouvelle politique avec les permissions nécessaires pour accéder à votre bucket S3 :
   ```json
   {
       "Version": "2012-10-17",
       "Statement": [
           {
               "Effect": "Allow",
               "Action": [
                   "s3:PutObject",
                   "s3:GetObject",
                   "s3:DeleteObject"
               ],
               "Resource": "arn:aws:s3:::your-bucket-name/*"
           }
       ]
   }
   ```

### Étape 2 : Attacher la politique à un utilisateur IAM
1. Créez un utilisateur IAM ou utilisez un utilisateur existant.
2. Attachez la politique IAM créée à cet utilisateur.

### Exercice
1. Créez une politique IAM pour permettre l'accès à votre bucket S3.
2. Attachez la politique à un utilisateur IAM.

**Corrigé de l'exercice :**
1. Créez une politique IAM avec le JSON ci-dessus.
2. Attachez cette politique à un utilisateur IAM existant ou nouveau.

## Chapitre-03 Développement de l'application FastAPI

### Partie-01 Installation de FastAPI et des dépendances

### Étape 1 : Installation de Python et FastAPI
1. Installez Python 3 si ce n'est pas déjà fait.
2. Installez FastAPI et Uvicorn :
   ```bash
   pip install fastapi uvicorn boto3
   ```

### Étape 2 : Création d'une application FastAPI de base
1. Créez un fichier `main.py` :
   ```python
   from fastapi import FastAPI

   app = FastAPI()

   @app.get("/")
   def read_root():
       return {"Hello": "World"}
   ```

### Exercice
1. Installez FastAPI et Uvicorn.
2. Créez un fichier `main.py` avec une application FastAPI de base.

**Corrigé de l'exercice :**
1. Installez FastAPI et Uvicorn :
   ```bash
   pip install fastapi uvicorn boto3
   ```
2. Créez un fichier `main.py` :
   ```python
   from fastapi import FastAPI

   app = FastAPI()

   @app.get("/")
   def read_root():
       return {"Hello": "World"}
   ```

### Partie-02 Intégration avec S3 pour le stockage de fichiers

### Étape 1 : Configuration de l'accès à S3
1. Ajoutez la configuration d'accès S3 dans votre fichier `main.py` :
   ```python
   import boto3
   from fastapi import FastAPI, File, UploadFile
   from botocore.exceptions import NoCredentialsError

   app = FastAPI()

   s3_client = boto3.client('s3', aws_access_key_id='your-access-key-id',
                            aws_secret_access_key='your-secret-access-key',
                            region_name='your-region')

   BUCKET_NAME = 'your-bucket-name'

   @app.post("/uploadfile/")
   async def upload_file(file: UploadFile = File(...)):
       try:
           s3_client.upload_fileobj(file.file, BUCKET_NAME, file.filename)
           return {"filename": file.filename}
       except NoCredentialsError:
           return {"error": "Credentials not available"}
   ```

### Étape 2 : Test de l'upload de fichiers
1. Lancez l'application FastAPI :
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000
   ```
2. Utilisez un outil comme `curl` ou l'interface de documentation interactive de FastAPI pour tester l'upload de fichiers.

### Exercice
1. Configurez l'accès à S3 dans votre application FastAPI.
2. Testez l'upload de fichiers vers S3.

**Corrigé de l'exercice :**
1. Configurez l'accès à S3 dans `main.py` :
   ```python
   import boto3
   from fastapi import FastAPI, File, UploadFile
   from botocore.exceptions import NoCredentialsError

   app = FastAPI()

   s3_client = boto3.client('s3', aws_access_key_id='your-access-key-id',
                            aws_secret_access_key='your-secret-access-key',
                            region_name='your-region')

   BUCKET_NAME = 'your-bucket-name'

   @app.post("/uploadfile/")
   async def upload_file(file: UploadFile = File(...)):
       try:
           s3_client.upload_fileobj(file.file, BUCKET_NAME, file.filename)
           return {"filename": file.filename}
       except NoCredentialsError:
           return {"error": "Credentials not available"}
   ```
2. Lancez l'application et testez l'upload de fichiers :
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000
   ```

## Chapitre-04 Déploiement de l'application FastAPI sur EC2

### Partie-01 Configuration de l'instance EC2

### Étape 1 : Lancer une instance EC2
1. Connectez-vous à la console AWS.
2. Allez dans "Services" et sélectionnez "EC2".
3. Cliquez sur "Lancer une instance".
4. Suivez les étapes pour configurer votre instance :
   - Choisissez une AMI (Amazon Machine Image).
   - Sélectionnez un type d'instance (par exemple, t2.micro).
   - Configurez les détails de l'instance.
   - Ajoutez du stockage.
   - Configurez les groupes de sécurité pour autoriser le trafic HTTP (port 80) et le trafic de l'API (port 8000).

### Étape 2 : Connexion à l'instance EC2
1. Téléchargez le fichier .pem de votre

 clé privée si vous ne l'avez pas déjà.
2. Modifiez les permissions de la clé pour qu'elle soit sécurisée :
   ```bash
   chmod 400 your-key.pem
   ```
3. Connectez-vous à l'instance EC2 en utilisant SSH :
   ```bash
   ssh -i your-key.pem ec2-user@your-ec2-ip
   ```

### Exercice
1. Lancez une instance EC2 en suivant les étapes ci-dessus.
2. Configurez les groupes de sécurité et connectez-vous à l'instance via SSH.

**Corrigé de l'exercice :**
1. Suivez les étapes dans la console AWS pour lancer une instance EC2.
2. Configurez les groupes de sécurité pour autoriser le trafic HTTP et API, puis connectez-vous à l'instance :
   ```bash
   chmod 400 your-key.pem
   ssh -i your-key.pem ec2-user@your-ec2-ip
   ```

### Partie-02 Déploiement de l'application FastAPI sur EC2

### Étape 1 : Installation de Python et des dépendances
1. Connectez-vous à votre instance EC2.
2. Installez Python 3 et les dépendances :
   ```bash
   sudo yum update -y
   sudo yum install python3 -y
   pip3 install fastapi uvicorn boto3
   ```

### Étape 2 : Transfert des fichiers de l'application
1. Transférez votre fichier `main.py` et d'autres fichiers nécessaires sur l'instance EC2 :
   ```bash
   scp -i your-key.pem main.py ec2-user@your-ec2-ip:/home/ec2-user/
   ```

### Étape 3 : Configuration de Systemd pour gérer l'application
1. Créez un fichier de service Systemd pour votre application FastAPI :
   ```bash
   sudo vi /etc/systemd/system/fastapi.service
   ```
2. Ajoutez le contenu suivant :
   ```ini
   [Unit]
   Description=FastAPI application
   After=network.target

   [Service]
   User=ec2-user
   Group=ec2-user
   WorkingDirectory=/home/ec2-user
   ExecStart=/usr/local/bin/uvicorn main:app --host 0.0.0.0 --port 8000

   [Install]
   WantedBy=multi-user.target
   ```

### Étape 4 : Démarrage et activation du service
1. Rechargez Systemd pour appliquer les modifications :
   ```bash
   sudo systemctl daemon-reload
   ```
2. Démarrez le service FastAPI :
   ```bash
   sudo systemctl start fastapi
   ```
3. Activez le service pour qu'il démarre au boot :
   ```bash
   sudo systemctl enable fastapi
   ```

### Exercice
1. Installez Python et les dépendances sur l'instance EC2.
2. Transférez votre application et configurez Systemd pour gérer le service.

**Corrigé de l'exercice :**
1. Installez Python et les dépendances :
   ```bash
   sudo yum update -y
   sudo yum install python3 -y
   pip3 install fastapi uvicorn boto3
   ```
2. Transférez votre application et configurez Systemd :
   ```bash
   scp -i your-key.pem main.py ec2-user@your-ec2-ip:/home/ec2-user/
   sudo vi /etc/systemd/system/fastapi.service
   ```
   Ajoutez le contenu suivant :
   ```ini
   [Unit]
   Description=FastAPI application
   After=network.target

   [Service]
   User=ec2-user
   Group=ec2-user
   WorkingDirectory=/home/ec2-user
   ExecStart=/usr/local/bin/uvicorn main:app --host 0.0.0.0 --port 8000

   [Install]
   WantedBy=multi-user.target
   ```
3. Rechargez Systemd, démarrez et activez le service :
   ```bash
   sudo systemctl daemon-reload
   sudo systemctl start fastapi
   sudo systemctl enable fastapi
   ```

### Partie-03 Vérification du déploiement

### Étape 1 : Tester l'API
1. Ouvrez un navigateur web ou utilisez `curl` pour accéder à votre API :
   ```bash
   curl http://your-ec2-ip:8000/
   ```

### Exercice
1. Testez votre API en accédant à l'endpoint racine.

**Corrigé de l'exercice :**
1. Testez l'API avec `curl` :
   ```bash
   curl http://your-ec2-ip:8000/
   ```


---
## Introduction aux Modèles de Services Cloud : SaaS, PaaS, IaaS, et DaaS

Les services cloud sont devenus un pilier essentiel dans l'infrastructure informatique moderne, permettant aux entreprises de se concentrer sur leurs activités principales sans se soucier des détails techniques de gestion des systèmes informatiques. Les modèles de services cloud les plus courants sont le SaaS (Software as a Service), le PaaS (Platform as a Service), l'IaaS (Infrastructure as a Service) et le DaaS (Desktop as a Service). Ce cours explore chacun de ces modèles en détail.

### 1. SaaS (Software as a Service)

**Définition :**
Le SaaS est un modèle de distribution de logiciels dans lequel les applications sont hébergées par un fournisseur de services et mises à la disposition des clients via Internet.

**Caractéristiques :**
- Accès via Internet
- Pas besoin d'installation locale
- Mise à jour automatique
- Abonnement mensuel ou annuel

**Exemples :**
- Google Workspace (anciennement G Suite)
- Microsoft Office 365
- Salesforce
- Slack

**Avantages :**
- Facilité d'accès et d'utilisation
- Coûts réduits de maintenance
- Flexibilité et évolutivité

**Inconvénients :**
- Dépendance à une connexion Internet
- Moins de contrôle sur les données
- Problèmes potentiels de sécurité et de confidentialité

### 2. PaaS (Platform as a Service)

**Définition :**
Le PaaS fournit une plateforme et un environnement permettant aux développeurs de construire des applications et des services sur Internet.

**Caractéristiques :**
- Environnement de développement complet
- Outils de développement intégrés
- Gestion des bases de données, du middleware et des services

**Exemples :**
- Google App Engine
- Microsoft Azure
- Heroku
- IBM Cloud Foundry

**Avantages :**
- Réduction du temps de développement
- Gestion simplifiée de l'infrastructure
- Support pour le cycle de vie complet des applications

**Inconvénients :**
- Limité par les outils et langages pris en charge par le fournisseur
- Problèmes potentiels de verrouillage du fournisseur
- Coûts imprévus en cas de croissance rapide

### 3. IaaS (Infrastructure as a Service)

**Définition :**
L'IaaS offre une infrastructure informatique virtualisée et automatisée via Internet. Les utilisateurs peuvent louer des ressources telles que des serveurs, du stockage et des réseaux.

**Caractéristiques :**
- Ressources informatiques virtualisées
- Facturation à l'utilisation
- Évolutivité et flexibilité

**Exemples :**
- Amazon Web Services (AWS)
- Microsoft Azure
- Google Cloud Platform (GCP)
- IBM Cloud

**Avantages :**
- Contrôle total sur l'infrastructure
- Évolutivité à la demande
- Modèle de coûts flexible

**Inconvénients :**
- Complexité de la gestion
- Nécessite des compétences techniques avancées
- Problèmes potentiels de sécurité

### 4. DaaS (Desktop as a Service)

**Définition :**
Le DaaS fournit des postes de travail virtuels hébergés dans le cloud, accessibles via Internet.

**Caractéristiques :**
- Environnement de bureau hébergé
- Accès à distance sécurisé
- Gestion centralisée

**Exemples :**
- Amazon WorkSpaces
- Microsoft Windows Virtual Desktop
- Citrix Virtual Apps and Desktops
- VMware Horizon Cloud

**Avantages :**
- Accès à distance et mobilité
- Sécurité et conformité renforcées
- Réduction des coûts de matériel

**Inconvénients :**
- Dépendance à une connexion Internet
- Performance variable selon la qualité de la connexion
- Coûts récurrents

### Comparaison des Modèles de Services Cloud

| Caractéristique | SaaS | PaaS | IaaS | DaaS |
|-----------------|------|------|------|------|
| **Utilisateurs cibles** | Utilisateurs finaux | Développeurs | Administrateurs système | Employés distants |
| **Gestion des ressources** | Fournisseur | Fournisseur | Utilisateur | Fournisseur |
| **Exemples** | Google Workspace, Salesforce | Google App Engine, Heroku | AWS, Azure | Amazon WorkSpaces, Citrix |
| **Avantages principaux** | Facilité d'utilisation, mises à jour automatiques | Rapidité de développement, intégration d'outils | Contrôle total, flexibilité | Mobilité, sécurité |
| **Inconvénients** | Moins de contrôle, dépendance Internet | Verrouillage fournisseur, coûts imprévus | Complexité, compétences techniques | Dépendance Internet, coûts |

